<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>LLMs on Ravikanth Chaganti</title>
    <link>https://ravichaganti.com/categories/llms/</link>
    <description>Recent content in LLMs on Ravikanth Chaganti</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 16 Feb 2026 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://ravichaganti.com/categories/llms/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Implementing llms.txt and Markdown Output in Hugo</title>
      <link>https://ravichaganti.com/blog/implementing-llms.txt-and-markdown-output-in-hugo/</link>
      <pubDate>Mon, 16 Feb 2026 00:00:00 +0000</pubDate>
      <guid>https://ravichaganti.com/blog/implementing-llms.txt-and-markdown-output-in-hugo/</guid>
      <description>&lt;p&gt;As AI agents and Large Language Models (LLMs) become a primary way for users (and other agents) to consume technical content, the way we serve our websites needs to evolve. While HTML is great for human readability in a browser, it&amp;rsquo;s often cluttered with navigation, sidebars, and styling that can confuse or distract an AI agent. The emerging &lt;a href=&#34;https://llmstxt.org/&#34;&gt;llms.txt&lt;/a&gt; standard addresses this by providing a structured, Markdown-based map of your site&amp;rsquo;s content specifically for AI consumption. I recently wrote about the &lt;a href=&#34;https://ravichaganti.com/blog/documentation-stack-for-ai-agents/&#34;&gt;documentation stack for AI agents&lt;/a&gt;, and thought it was time to practice what I preach.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
