<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Openai on Ravikanth Chaganti</title>
    <link>https://ravichaganti.com/categories/openai/</link>
    <description>Recent content in Openai on Ravikanth Chaganti</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 10 Jan 2025 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://ravichaganti.com/categories/openai/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Predicted outputs in Azure OpenAI</title>
      <link>https://ravichaganti.com/blog/predicted-outputs-azure-openai/</link>
      <pubDate>Fri, 10 Jan 2025 00:00:00 +0000</pubDate>
      <guid>https://ravichaganti.com/blog/predicted-outputs-azure-openai/</guid>
      <description>&lt;p&gt;Sometimes, you may want the LLM to perform only minimal changes to what is provided as a prompt. For example, you have a couple of paragraphs of text that you want the LLM to modify to ensure no spelling mistakes. You do not want the LLM to change the overall content, but make sure the misspellings are corrected. This usually helps in reducing the LLM response latency. This is useful in scenarios where you already know a large portion of the expected response and is well-suited for code completion and error detection scenarios. In this part of the &lt;a href=&#34;https://ravichaganti.com/series/azure-openai/&#34;&gt;series of articles on Azure OpenAI&lt;/a&gt;, we will use predicted outputs with Azure OpenAI to build AI applications.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Parallel tool calling in Azure OpenAI</title>
      <link>https://ravichaganti.com/blog/parallel-tool-calling-azure-openai/</link>
      <pubDate>Tue, 20 Aug 2024 00:00:00 +0000</pubDate>
      <guid>https://ravichaganti.com/blog/parallel-tool-calling-azure-openai/</guid>
      <description>&lt;p&gt;We have learned to perform single- and multi-tool calling with the Azure OpenAI API for chat completions. This part of the &lt;a href=&#34;https://ravichaganti.com/series/azure-openai/&#34;&gt;series&lt;/a&gt; on Azure OpenAI will describe the parallel tool calling feature and how to implement it. Parallel tool calling allows you to perform multiple calls together. This enables parallel execution, result retrieval, and fewer calls to the LLM. Parallelizing tool calls improves overall performance.&lt;/p&gt;&#xA;&lt;p&gt;In a previous example on retrieving weather at a given location, we examined how to iterate over the LLM response for tool calls and append it to the conversation history before making the next LLM API call.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Structured output in Azure OpenAI</title>
      <link>https://ravichaganti.com/blog/structured-output-azure-openai/</link>
      <pubDate>Sun, 18 Aug 2024 00:00:00 +0000</pubDate>
      <guid>https://ravichaganti.com/blog/structured-output-azure-openai/</guid>
      <description>&lt;p&gt;In this &lt;a href=&#34;https://ravichaganti.com/series/azure-openai/&#34;&gt;series&lt;/a&gt;, we have examined the basics of Azure Open AI, using the chat completions API, streaming responses, and finally, single and multi-tool calling. In today&amp;rsquo;s article, we will examine how to return structured output from the LLM response. We will first examine structured output without function calling and then update the earlier multi-function calling example to output JSON instead of text.&lt;/p&gt;&#xA;&lt;p&gt;Structured outputs tell an LLM to follow the schema represented by the &lt;code&gt;response_format&lt;/code&gt; parameter of a request to the LLM. We can use &lt;a href=&#34;https://docs.pydantic.dev/latest/&#34;&gt;Pydantic&lt;/a&gt; to build the schema.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Implementing multiple tool/function calling when using Azure OpenAI</title>
      <link>https://ravichaganti.com/blog/azure-openai-function-calling-with-multiple-tools/</link>
      <pubDate>Fri, 16 Aug 2024 00:00:00 +0000</pubDate>
      <guid>https://ravichaganti.com/blog/azure-openai-function-calling-with-multiple-tools/</guid>
      <description>&lt;p&gt;In the &lt;a href=&#34;https://ravichaganti.com/blog/azure-openai-function-calling/&#34;&gt;last article&lt;/a&gt; of &lt;a href=&#34;https://ravichaganti.com/series/azure-openai/&#34;&gt;this series&lt;/a&gt;, we learned about function/tool calling. Based on the prompt, the LLM indicates that we must call the &lt;code&gt;get_weather&lt;/code&gt; tool. The LLM finally returns the answer to our prompt using the tool response. However, let us try to add a few more variables to our prompt. The updated prompt will be &amp;ldquo;What&amp;rsquo;s the weather like in Bengaluru next week?&amp;rdquo;.&lt;/p&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;&#xA;&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;&#xA;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1&#xA;&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2&#xA;&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3&#xA;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&#xA;&lt;td class=&#34;lntd&#34;&gt;&#xA;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;$ python .\05_function_calling.py&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;get_current_time called with location: Bengaluru&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;The current temperature in Bengaluru is approximately 28.2Â°C. However, for next week&amp;#39;s weather prediction, you&amp;#39;d need a forecast service as I currently provide only current weather information.&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&#xA;&lt;/div&gt;&#xA;&lt;/div&gt;&lt;p&gt;LLM uses the &lt;code&gt;get_weather&lt;/code&gt; tool to determine the current weather but fails to determine next week&amp;rsquo;s weather. This is because we have not provided any tool for the LLM to determine what next week means. Determining the meaning of next week requires the knowledge of the current date and time. This article will demonstrate how to add multiple tool-calling capabilities to our program. With the updated script, you can receive the weather information for a specific date.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Implementing tool/function calling when using Azure OpenAI</title>
      <link>https://ravichaganti.com/blog/azure-openai-function-calling/</link>
      <pubDate>Mon, 12 Aug 2024 00:00:00 +0000</pubDate>
      <guid>https://ravichaganti.com/blog/azure-openai-function-calling/</guid>
      <description>&lt;p&gt;In the last article of &lt;a href=&#34;https://ravichaganti.com/series/azure-openai/&#34;&gt;this series&lt;/a&gt;, we learned how to use the chat completion API. Towards the end, we learned that the LLMs have a knowledge cut-off date and no real-time access to information. However, this can be bridged using the tool/function calling feature of Azure OpenAI service. In this article, we shall learn how to implement tool calling.&lt;/p&gt;&#xA;&lt;p&gt;Azure OpenAI&amp;rsquo;s function calling capability lets you connect your language models to external tools and APIs, enabling them to perform a wider range of tasks and access real-time information. This opens up a world of possibilities, allowing your models to interact with the real world in ways never imagined.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Using chat completion API in Azure OpenAI</title>
      <link>https://ravichaganti.com/blog/using-chat-completion-api-azure-openai/</link>
      <pubDate>Thu, 08 Aug 2024 00:00:00 +0000</pubDate>
      <guid>https://ravichaganti.com/blog/using-chat-completion-api-azure-openai/</guid>
      <description>&lt;p&gt;So far in &lt;a href=&#34;https://ravichaganti.com/series/azure-openai/&#34;&gt;this series&lt;/a&gt;, we have looked at the Azure OpenAI completion API, which generates a response for a given prompt. This is a legacy API, and using the chat completion API is recommended. We can build conversational chatbots and similar applications with the chat completion API. This article will examine how to use the Azure OpenAI chat completion API. In the earlier articles, we used the &lt;code&gt;client.completions.create()&lt;/code&gt; function to generate a response. We need to use the &lt;code&gt;client.chat.completions.create()&lt;/code&gt; in the &lt;code&gt;openai&lt;/code&gt; library to build a conversation with the LLM.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Streaming model responses when using Azure OpenAI</title>
      <link>https://ravichaganti.com/blog/streaming-completions-azure-openai/</link>
      <pubDate>Sun, 04 Aug 2024 00:00:00 +0000</pubDate>
      <guid>https://ravichaganti.com/blog/streaming-completions-azure-openai/</guid>
      <description>&lt;p&gt;Responses are streamed to the user interface as they are generated using ChatGPT and similar tools. This eliminates the need for the user to wait until the complete response is generated. In today&amp;rsquo;s article, we shall look at streaming LLM-generated responses when using Azure OpenAI API in Python.  In the earlier part of &lt;a href=&#34;https://ravichaganti.com/series/azure-openai/&#34;&gt;this series&lt;/a&gt;, we learned about the &lt;code&gt;client.completions.create()&lt;/code&gt; function used to send a prompt to the LLM and retrieve one or more responses. This function supports a parameter called &lt;code&gt;stream&lt;/code&gt; when set to &lt;code&gt;True&lt;/code&gt;, asks LLM to stream the response as it gets generated. The way to handle this response is a bit different from a standard completion response.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Getting started with Azure OpenAI</title>
      <link>https://ravichaganti.com/blog/getting-started-with-azure-openai/</link>
      <pubDate>Thu, 01 Aug 2024 00:00:00 +0000</pubDate>
      <guid>https://ravichaganti.com/blog/getting-started-with-azure-openai/</guid>
      <description>&lt;p&gt;Generative AI and &lt;a href=&#34;https://openai.com/&#34;&gt;OpenAI&lt;/a&gt; should not be alien anymore. Several startups are already riding this new wave and creating stunning applications that solve several important use cases. I use GenAI regularly to learn and become more efficient in coding. GitHub Copilot has been a good friend. I experimented with creating Large Language Model (LLM) applications using different providers (&lt;a href=&#34;https://platform.openai.com/docs/overview&#34;&gt;OpenAI&lt;/a&gt; and &lt;a href=&#34;https://ai.google.dev/&#34;&gt;Google Gemini&lt;/a&gt;) and in different programming languages. OpenAI provides client libraries that can be used with any provider that offers an OpenAI-compatible API. For example, we can use the &lt;a href=&#34;https://pypi.org/project/openai/&#34;&gt;OpenAI Python library&lt;/a&gt; to work with OpenAI and Azure OpenAI services.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
