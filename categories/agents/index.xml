<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Agents on Ravikanth Chaganti</title>
    <link>https://ravichaganti.com/categories/agents/</link>
    <description>Recent content in Agents on Ravikanth Chaganti</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 10 Feb 2026 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://ravichaganti.com/categories/agents/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Documentation stack for AI agents</title>
      <link>https://ravichaganti.com/blog/documentation-stack-for-ai-agents/</link>
      <pubDate>Tue, 10 Feb 2026 00:00:00 +0000</pubDate>
      <guid>https://ravichaganti.com/blog/documentation-stack-for-ai-agents/</guid>
      <description>&lt;p&gt;We are in the middle of a fundamental shift in how software gets built. LLMs are no longer used as passive autocomplete machines. AI agents reason, plan, retrieve information, and act. An agent is only as good as the knowledge it can access. An LLM&amp;rsquo;s training data is frozen in time. The Kubernetes API changed last week. Your company shipped a new SDK version this morning. The compliance rules were updated yesterday. If an agent can&amp;rsquo;t reach this knowledge at inference time, it hallucinates, generates deprecated code, or simply gives up.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Cross-Framework Agent Communication: Microsoft Agent Framework meets Google ADK via A2A</title>
      <link>https://ravichaganti.com/blog/cross-framework-agent-communication-microsoft-agent-framework-meets-google-adk-via-a2a/</link>
      <pubDate>Wed, 28 Jan 2026 00:00:00 +0000</pubDate>
      <guid>https://ravichaganti.com/blog/cross-framework-agent-communication-microsoft-agent-framework-meets-google-adk-via-a2a/</guid>
      <description>&lt;p&gt;In the &lt;a href=&#34;https://ravichaganti.com/blog/building-multi-agent-systems-with-google-adk-and-the-a2a-protocol/&#34;&gt;previous article&lt;/a&gt;, we explored how to build multi-agent systems using Google&amp;rsquo;s Agent Development Kit (ADK) and the A2A (Agent-to-Agent) protocol. We built a currency conversion agent and exposed it via A2A, then created a travel assistant that consumed it—all within the ADK ecosystem.&lt;/p&gt;&#xA;&lt;p&gt;But here&amp;rsquo;s where A2A truly shines: framework interoperability. The A2A protocol isn&amp;rsquo;t tied to any specific agent framework. Any A2A-compliant agent can communicate with any other, regardless of whether it was built with Google ADK, Microsoft Agent Framework, LangChain, or a custom implementation.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Building multi-agent systems with Google ADK and the A2A protocol</title>
      <link>https://ravichaganti.com/blog/building-multi-agent-systems-with-google-adk-and-the-a2a-protocol/</link>
      <pubDate>Tue, 27 Jan 2026 00:00:00 +0000</pubDate>
      <guid>https://ravichaganti.com/blog/building-multi-agent-systems-with-google-adk-and-the-a2a-protocol/</guid>
      <description>&lt;p&gt;The landscape of AI agents is evolving rapidly, and one of the most significant developments is the emergence of standardized protocols that enable agents to communicate with one another. Google&amp;rsquo;s Agent Development Kit (ADK) natively supports the Agent-to-Agent (A2A) protocol, enabling developers to build sophisticated multi-agent systems where specialized agents can collaborate across network boundaries. In this post, we&amp;rsquo;ll explore what A2A is, why it matters, and walk through a complete implementation that demonstrates how to expose an agent as a remote service and consume it from another agent.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Building a Multi-Agent LinkedIn Newsletter System with Google ADK</title>
      <link>https://ravichaganti.com/blog/building-a-multi-agent-linkedin-newsletter-system-with-google-adk/</link>
      <pubDate>Mon, 26 Jan 2026 00:00:00 +0000</pubDate>
      <guid>https://ravichaganti.com/blog/building-a-multi-agent-linkedin-newsletter-system-with-google-adk/</guid>
      <description>&lt;p&gt;Google&amp;rsquo;s Agent Development Kit (ADK) provides &lt;a href=&#34;https://google.github.io/adk-docs/agents/workflow-agents/&#34;&gt;workflow agents&lt;/a&gt; to enable more deterministic agent execution. These workflows can be combined to create more complex agentic workflows.&lt;/p&gt;&#xA;&lt;p&gt;In this post, I&amp;rsquo;ll walk you through how I created an AI-powered content pipeline that:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Researches&lt;/strong&gt; trending topics using Google Search&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Writes&lt;/strong&gt; engaging newsletter drafts&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Edits&lt;/strong&gt; and quality-checks the content&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Publishes&lt;/strong&gt; the final version to a local file&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;Let&amp;rsquo;s dive in!&lt;/p&gt;&#xA;&lt;h3 id=&#34;the-big-picture-a-team-of-specialized-agents&#34;&gt;The Big Picture: A Team of Specialized Agents&lt;/h3&gt;&#xA;&lt;p&gt;Instead of building one massive AI that does everything (and probably does nothing well), I went with a &lt;strong&gt;multi-agent architecture&lt;/strong&gt;. Think of it like assembling a content team:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Google ADK - Sessions, state, and memory</title>
      <link>https://ravichaganti.com/blog/google-adk-sessions-state-and-memory/</link>
      <pubDate>Fri, 05 Dec 2025 00:00:00 +0000</pubDate>
      <guid>https://ravichaganti.com/blog/google-adk-sessions-state-and-memory/</guid>
      <description>&lt;p&gt;Imagine you built a travel-booking agent. A user says, &amp;ldquo;Find flights to Paris, and the agent returns options. Then the user says, &amp;ldquo;Book the second one.&amp;rdquo; Without any memory of the previous turn, the agent has no idea what &amp;ldquo;the second one&amp;rdquo; refers to. The conversation is dead. This is the fundamental problem with LLMs. LLMs are stateless. Every API call to an LLM is independent. The model does not inherently remember what was said before. Yet meaningful conversations are inherently multi-turn, contextual, and stateful. This is where agent memory comes into play. Agent memory is the system built around the LLM to allow it to retain information, learn from past interactions, and maintain continuity within and across conversations.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Google ADK - types of agents</title>
      <link>https://ravichaganti.com/blog/google-adk-types-of-agents/</link>
      <pubDate>Wed, 03 Dec 2025 00:00:00 +0000</pubDate>
      <guid>https://ravichaganti.com/blog/google-adk-types-of-agents/</guid>
      <description>&lt;p&gt;In the introduction to Google ADK, we looked at the basics of using ADK to create an agent, connect tools, and also learnt how to define agents using the declarative YAML configuration. The example we implemented used the &lt;code&gt;Agent&lt;/code&gt; class. This class is an alias of the &lt;code&gt;LlmAgent&lt;/code&gt; class. &lt;code&gt;LlmAgent&lt;/code&gt; behavior is non-deterministic as it uses an LLM for deciding what tools to use or how to proceed toward a goal. ADK also offers &lt;a href=&#34;https://google.github.io/adk-docs/agents/workflow-agents/&#34;&gt;workflow agents&lt;/a&gt; that are more deterministic, control the execution flow of their sub-agents, and operate according to predefined logic. The execution flow of workflow agents depends on their type.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Introduction to Google Agent Development Kit</title>
      <link>https://ravichaganti.com/blog/introduction-to-google-agent-development-kit/</link>
      <pubDate>Mon, 01 Dec 2025 00:00:00 +0000</pubDate>
      <guid>https://ravichaganti.com/blog/introduction-to-google-agent-development-kit/</guid>
      <description>&lt;p&gt;Every other week, we see a new framework claiming to simplifythe  development of AI agents. Thanks to the growing interest in agentic AI. Earlier this year, Google released its framework for developing agents, which it called the Agent Development Kit (ADK).&lt;/p&gt;&#xA;&lt;div class=&#34;youtube-embed&#34; style=&#34;max-width: 100%; margin: 1.5rem auto;&#34;&gt;&#xA;  &#xA;  &lt;div id=&#34;youtube-2d93e79017b3ec8606e6135d3548ef28-placeholder&#34; class=&#34;youtube-placeholder hidden&#34;&gt;&#xA;    &lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden; border-radius: 0.5rem; background: linear-gradient(135deg, #1a1a1a 0%, #2d2d2d 100%);&#34;&gt;&#xA;      &lt;div style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; display: flex; flex-direction: column; align-items: center; justify-content: center; padding: 2rem; text-align: center;&#34;&gt;&#xA;        &#xA;        &lt;svg style=&#34;width: 4rem; height: 4rem; margin-bottom: 1rem; opacity: 0.9;&#34; viewBox=&#34;0 0 24 24&#34; fill=&#34;#FF0000&#34;&gt;&#xA;          &lt;path d=&#34;M23.498 6.186a3.016 3.016 0 0 0-2.122-2.136C19.505 3.545 12 3.545 12 3.545s-7.505 0-9.377.505A3.017 3.017 0 0 0 .502 6.186C0 8.07 0 12 0 12s0 3.93.502 5.814a3.016 3.016 0 0 0 2.122 2.136c1.871.505 9.376.505 9.376.505s7.505 0 9.377-.505a3.015 3.015 0 0 0 2.122-2.136C24 15.93 24 12 24 12s0-3.93-.502-5.814zM9.545 15.568V8.432L15.818 12l-6.273 3.568z&#34;/&gt;&#xA;        &lt;/svg&gt;&#xA;&#xA;        &lt;h4 style=&#34;color: #ffffff; font-size: 1.125rem; font-weight: 600; margin-bottom: 0.5rem;&#34;&gt;&#xA;          YouTube Video&#xA;        &lt;/h4&gt;&#xA;        &lt;p style=&#34;color: #cccccc; font-size: 0.875rem; margin-bottom: 1.5rem; max-width: 400px;&#34;&gt;&#xA;          This video requires your consent to load content from YouTube, which may set tracking cookies.&#xA;        &lt;/p&gt;</description>
    </item>
    <item>
      <title>Magentic workflows in Microsoft Agent Framework</title>
      <link>https://ravichaganti.com/blog/magentic-workflows-in-microsoft-agent-framework/</link>
      <pubDate>Mon, 20 Oct 2025 00:00:00 +0000</pubDate>
      <guid>https://ravichaganti.com/blog/magentic-workflows-in-microsoft-agent-framework/</guid>
      <description>&lt;p&gt;In this series on Microsoft Agent Framework (MAF), we&amp;rsquo;ve explored &lt;a href=&#34;https://ravichaganti.com/blog/sequential-workflows-in-microsoft-agent-framework/&#34;&gt;sequential workflows&lt;/a&gt; where agents process tasks in a fixed order, &lt;a href=&#34;https://ravichaganti.com/blog/concurrent-workflows-in-microsoft-agent-framework/&#34;&gt;concurrent workflows&lt;/a&gt; where agents work in parallel, &lt;a href=&#34;https://ravichaganti.com/blog/handoff-workflows-in-microsoft-agent-framework/&#34;&gt;handoff workflows&lt;/a&gt; where agents transfer control based on context, and &lt;a href=&#34;https://ravichaganti.com/blog/group-chat-workflows-in-microsoft-agent-framework/&#34;&gt;group chat workflows&lt;/a&gt; where agents engage in turn-based discussions. Each pattern has its strengths, but they all share one limitation: the orchestration logic is predetermined at design time.&lt;/p&gt;&#xA;&lt;p&gt;What if you need a workflow that can adapt its routing decisions based on what agents discover during execution? Enter Magentic workflows, the most sophisticated orchestration pattern in MAF, where an LLM-powered manager autonomously coordinates specialized agents, making real-time decisions about who to invoke next based on intermediate results.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Group chat workflows in Microsoft Agent Framework</title>
      <link>https://ravichaganti.com/blog/group-chat-workflows-in-microsoft-agent-framework/</link>
      <pubDate>Sat, 18 Oct 2025 00:00:00 +0000</pubDate>
      <guid>https://ravichaganti.com/blog/group-chat-workflows-in-microsoft-agent-framework/</guid>
      <description>&lt;p&gt;In the previous articles of this &lt;a href=&#34;https://ravichaganti.com/series/microsoft-agent-framework/&#34;&gt;series&lt;/a&gt;, we explored three powerful workflow patterns in Microsoft Agent Framework (MAF):&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Sequential: Agents process in a fixed order, like a pipeline.&lt;/li&gt;&#xA;&lt;li&gt;Concurrent: Agents work in parallel, with results aggregated.&lt;/li&gt;&#xA;&lt;li&gt;Handoff: A coordinator routes requests to specialist agents.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;But what happens when you need agents to discuss, debate, and build on each other&amp;rsquo;s ideas, like a brainstorming session or a committee meeting? This is where the &lt;code&gt;GroupChat&lt;/code&gt; workflow pattern shines. In this article, we&amp;rsquo;ll explore how to build dynamic multi-agent conversations using &lt;code&gt;GroupChatBuilder&lt;/code&gt;, where a moderator (or selection function) orchestrates turn-based discussions among participant agents.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Docker cagent - An introduction</title>
      <link>https://ravichaganti.com/blog/docker-cagent-an-introduction/</link>
      <pubDate>Thu, 16 Oct 2025 00:00:00 +0000</pubDate>
      <guid>https://ravichaganti.com/blog/docker-cagent-an-introduction/</guid>
      <description>&lt;p&gt;Docker is one company that has been really taking advantage of the AI wave. True to its philosophy, it is helping developers with new tools and frameworks to simplify AI application development. Starting with Docker MCP catalog, MCP toolkit, Model Runner, MCP gateway, and cagent, Docker is certainly at the forefront of AI agent developer experience. In this article, we will get started with &lt;code&gt;cagent&lt;/code&gt;.&lt;/p&gt;&#xA;&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://www.docker.com/blog/cagent-build-and-distribute-ai-agents-and-workflows/&#34;&gt;Docker &lt;code&gt;cagent&lt;/code&gt;&lt;/a&gt; is an &lt;a href=&#34;https://github.com/docker/cagent&#34;&gt;open-source&lt;/a&gt;, multi-agent AI runtime that lets you build, orchestrate, and share teams of specialized AI agents defined declaratively in YAML. Instead of wiring together complex agent frameworks in code, you describe what each agent does, which tools it can access, and how agents delegate to one another. &lt;code&gt;cagent&lt;/code&gt; handles the rest: model communication, tool orchestration, context isolation, and inter-agent coordination. It ships bundled with Docker Desktop 4.49+ and can distribute agent configurations as OCI artifacts through Docker Hub, treating agents with the same rigor as container images. Written in Go and currently labeled experimental, &lt;code&gt;cagent&lt;/code&gt; represents Docker&amp;rsquo;s bet that the agent ecosystem needs the same standardization, portability, and trust infrastructure that containers brought to application deployment.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Handoff workflows in Microsoft Agent Framework</title>
      <link>https://ravichaganti.com/blog/handoff-workflows-in-microsoft-agent-framework/</link>
      <pubDate>Thu, 16 Oct 2025 00:00:00 +0000</pubDate>
      <guid>https://ravichaganti.com/blog/handoff-workflows-in-microsoft-agent-framework/</guid>
      <description>&lt;p&gt;In the previous articles, we explored Sequential and Concurrent workflow patterns in the Microsoft Agent Framework (MAF). Today, we dive into one of the most practical and widely-applicable patterns: the handoff workflow. The handoff pattern models real-world scenarios in which a conversation or task is transferred from one agent to another based on context, expertise, or role. Think of it like a customer support call center—you first speak with a frontline agent who assesses your issue and then routes you to the appropriate specialist.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Concurrent workflows in Microsoft Agent Framework</title>
      <link>https://ravichaganti.com/blog/concurrent-workflows-in-microsoft-agent-framework/</link>
      <pubDate>Tue, 14 Oct 2025 00:00:00 +0000</pubDate>
      <guid>https://ravichaganti.com/blog/concurrent-workflows-in-microsoft-agent-framework/</guid>
      <description>&lt;p&gt;In the [previous article](&lt;a href=&#34;https://ravichaganti.com/blog/sequential-workflows-in-microsoft-agent-framework/&#34;&gt;Sequential workflows in Microsoft Agent Framework | Ravikanth Chaganti&lt;/a&gt;), we explored the sequential workflow pattern, a straightforward approach where agents process tasks one after another in a defined order. While sequential workflows are powerful for pipeline-style processing, they have a limitation: speed. When agents don&amp;rsquo;t depend on each other&amp;rsquo;s output, running them one at a time is inefficient.&lt;/p&gt;&#xA;&lt;p&gt;Here&amp;rsquo;s where the concurrent workflow pattern comes into play. This pattern allows multiple agents to work in parallel, dramatically reducing total execution time and enabling scenarios that require diverse perspectives to be analyzed simultaneously.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Sequential workflows in Microsoft Agent Framework</title>
      <link>https://ravichaganti.com/blog/sequential-workflows-in-microsoft-agent-framework/</link>
      <pubDate>Sun, 12 Oct 2025 00:00:00 +0000</pubDate>
      <guid>https://ravichaganti.com/blog/sequential-workflows-in-microsoft-agent-framework/</guid>
      <description>&lt;p&gt;A single AI agent is powerful and can do impressive things. But real-world applications often need multiple specialists working together, with each agent handling a specific task before passing results to the next. As with humans, in the agentic world we also need to break complex problems into manageable pieces and have specialized agents handle each task. We need one agent to review another&amp;rsquo;s work and handle complex tool invocation.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Building persistent AI Agents with Microsoft Agent Framework and Microsoft Foundry</title>
      <link>https://ravichaganti.com/blog/building-persistent-ai-agents-with-microsoft-agent-framework-and-microsoft-foundry/</link>
      <pubDate>Fri, 10 Oct 2025 00:00:00 +0000</pubDate>
      <guid>https://ravichaganti.com/blog/building-persistent-ai-agents-with-microsoft-agent-framework-and-microsoft-foundry/</guid>
      <description>&lt;p&gt;In my earlier post on &lt;a href=&#34;https://ravichaganti.com/blog/getting-started-with-foundry-agents/&#34;&gt;Getting Started with Foundry Agents&lt;/a&gt;, I covered the basics of creating agents using the Azure AI Foundry Agents service and the &lt;code&gt;azure-ai-projects&lt;/code&gt; SDK. In another article in this series, we looked at creating Azure AI agents with Microsoft Agent Framework (MAF). Agents created with MAF are local only where MAF acts as the runtime. In this follow-up, we will examine how to create Foundry agents using MAF.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Building AI Agents with Microsoft Agent Framework</title>
      <link>https://ravichaganti.com/blog/building-ai-agents-with-microsoft-agent-framework/</link>
      <pubDate>Sat, 04 Oct 2025 00:00:00 +0000</pubDate>
      <guid>https://ravichaganti.com/blog/building-ai-agents-with-microsoft-agent-framework/</guid>
      <description>&lt;p&gt;The &lt;strong&gt;Microsoft Agent Framework (MAF)&lt;/strong&gt; is an open-source development kit that combines the best ideas from Semantic Kernel and AutoGen projects. It provides a flexible foundation for building AI agents that can:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Process user inputs using Large Language Models (LLMs)&lt;/li&gt;&#xA;&lt;li&gt;Call tools and MCP servers to perform actions.&lt;/li&gt;&#xA;&lt;li&gt;Generate intelligent, context-aware responses.&lt;/li&gt;&#xA;&lt;li&gt;Manage conversation state across interactions.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;In this article, we&amp;rsquo;ll explore different examples that showcase different capabilities of AI agents.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Getting Started with Foundry Agents</title>
      <link>https://ravichaganti.com/blog/getting-started-with-foundry-agents/</link>
      <pubDate>Fri, 03 Oct 2025 00:00:00 +0000</pubDate>
      <guid>https://ravichaganti.com/blog/getting-started-with-foundry-agents/</guid>
      <description>&lt;p&gt;Microsoft Foundry (formerly Azure AI Foundry) is a unified system for building intelligent agents. It is a platform that provides models, tools, frameworks, and capabilities such as observability, guardrails, and enterprise-ready governance for building AI agents. With the Foundry Agent service, developers can develop agents locally and deploy them to different environments seamlessly, leveraging the building blocks provided by Microsoft Foundry. Foundry Agent service provides the runtime that manages conversations, orchestrates tool calls, and integrates with identify and observability systems. As discussed in the previous article, agents use LLMs to reason and make decisions. Agents use tools to perform actions. Agents can participate in workflows or interact with other agents to achieve a bigger goal. This is achieved by treating agents as composable units.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Introduction to Microsoft Agent Framework</title>
      <link>https://ravichaganti.com/blog/introduction-to-microsoft-agent-framework/</link>
      <pubDate>Thu, 02 Oct 2025 00:00:00 +0000</pubDate>
      <guid>https://ravichaganti.com/blog/introduction-to-microsoft-agent-framework/</guid>
      <description>&lt;p&gt;I have been following the Microsoft ecosystem for agent and agentic workflow development and have evaluated frameworks such as &lt;a href=&#34;https://github.com/microsoft/autogen&#34;&gt;AutoGen&lt;/a&gt; and &lt;a href=&#34;https://github.com/microsoft/semantic-kernel&#34;&gt;Semantic Kernel&lt;/a&gt;. In the past, I have written &lt;a href=&#34;https://ravichaganti.com/categories/autogen/&#34;&gt;briefly about AutoGen&lt;/a&gt;. I used Semantic Kernel, along with Azure AI Foundry, to experiment with a few enterprise-ready agentic scenarios. Both frameworks are useful in their own ways, and Semantic Kernel, with its enterprise-deployment readiness, became the go-to framework for many. Microsoft &lt;a href=&#34;https://devblogs.microsoft.com/foundry/introducing-microsoft-agent-framework-the-open-source-engine-for-agentic-ai-apps/&#34;&gt;announced plans to converge these frameworks&lt;/a&gt; into what it calls the Microsoft Agent Framework, which brings together the best parts of AutoGen and Semantic Kernel.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Building a Model Context Protocol server for Azure</title>
      <link>https://ravichaganti.com/blog/building-a-model-context-protocol-server-for-azure/</link>
      <pubDate>Tue, 25 Feb 2025 00:00:00 +0000</pubDate>
      <guid>https://ravichaganti.com/blog/building-a-model-context-protocol-server-for-azure/</guid>
      <description>&lt;p&gt;The &lt;a href=&#34;https://ravichaganti.com/blog/anthropic-model-context-protocol/&#34;&gt;earlier article&lt;/a&gt; in this &lt;a href=&#34;https://ravichaganti.com/series/mcp/&#34;&gt;series&lt;/a&gt; introduced Anthropic&amp;rsquo;s Model Context Protocol. It presented an example of building a simple MCP server for use with the Claude desktop application. The &lt;a href=&#34;https://github.com/rchaganti/mcp-servers/tree/main/hello-world&#34;&gt;hello-world example&lt;/a&gt; was a very basic implementation of an MCP server. In today&amp;rsquo;s article, we shall extend our knowledge of creating MCP servers to achieve more practical applications. We will build an MCP server to interact with Microsoft Azure resources.&lt;/p&gt;&#xA;&lt;p&gt;Anthropic made bootstrap MCP server development easy by providing the &lt;code&gt;create-mcp-server&lt;/code&gt; package. To get started, you need to install this locally as a tool.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Model Context Protocol by Anthropic for connecting AI models to data</title>
      <link>https://ravichaganti.com/blog/anthropic-model-context-protocol/</link>
      <pubDate>Sat, 01 Feb 2025 00:00:00 +0000</pubDate>
      <guid>https://ravichaganti.com/blog/anthropic-model-context-protocol/</guid>
      <description>&lt;p&gt;A couple of months ago, Anthropic introduced and open-sourced the &lt;a href=&#34;https://www.anthropic.com/news/model-context-protocol&#34;&gt;Model Context Protocol&lt;/a&gt; (MCP). MCP is the new standard for connecting AI models to external data sources and APIs more easily and consistently. With the advances in AI, models are becoming increasingly powerful in reasoning and quality. However, as text-completion machines, these models still lack access to real-time data. AI providers have worked around this using Retrieval Augmented Generation (RAG) and tool calling. Every data source requires custom implementation, and every provider has a way of integrating tools with AI models. MCP addresses these silos by providing a universal, open standard for connecting AI systems with data sources.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
