<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Google on Ravikanth Chaganti</title>
    <link>https://ravichaganti.com/categories/google/</link>
    <description>Recent content in Google on Ravikanth Chaganti</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Sat, 28 Feb 2026 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://ravichaganti.com/categories/google/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Google ADK - Agent Skills</title>
      <link>https://ravichaganti.com/blog/google-adk-agent-skills/</link>
      <pubDate>Sat, 28 Feb 2026 00:00:00 +0000</pubDate>
      <guid>https://ravichaganti.com/blog/google-adk-agent-skills/</guid>
      <description>&lt;p&gt;Every other week, we see a new framework claiming to simplify the development of AI agents. Thanks to the growing interest in agentic AI. Earlier this year, Google released its framework for developing agents, which it called the Agent Development Kit (ADK). In my &lt;a href=&#34;https://ravichaganti.com/blog/introduction-to-google-agent-development-kit/&#34;&gt;previous post&lt;/a&gt;, we explored the basics of creating an &lt;code&gt;LlmAgent&lt;/code&gt; and running it using ADK&amp;rsquo;s built-in tools.&lt;/p&gt;&#xA;&lt;p&gt;Today, we will dive into a powerful new feature in Google ADK: &lt;strong&gt;Agent Skills&lt;/strong&gt;. We will explore what Agent Skills are, why they matter, and how to implement a practical use case, an Azure Infrastructure as Code (IaC) agent that generates Bicep templates while strictly adhering to organizational governance rules.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Building multi-agent systems with Google ADK and the A2A protocol</title>
      <link>https://ravichaganti.com/blog/building-multi-agent-systems-with-google-adk-and-the-a2a-protocol/</link>
      <pubDate>Tue, 27 Jan 2026 00:00:00 +0000</pubDate>
      <guid>https://ravichaganti.com/blog/building-multi-agent-systems-with-google-adk-and-the-a2a-protocol/</guid>
      <description>&lt;p&gt;The landscape of AI agents is evolving rapidly, and one of the most significant developments is the emergence of standardized protocols that enable agents to communicate with one another. Google&amp;rsquo;s Agent Development Kit (ADK) natively supports the Agent-to-Agent (A2A) protocol, enabling developers to build sophisticated multi-agent systems where specialized agents can collaborate across network boundaries. In this post, we&amp;rsquo;ll explore what A2A is, why it matters, and walk through a complete implementation that demonstrates how to expose an agent as a remote service and consume it from another agent.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Building a Multi-Agent LinkedIn Newsletter System with Google ADK</title>
      <link>https://ravichaganti.com/blog/building-a-multi-agent-linkedin-newsletter-system-with-google-adk/</link>
      <pubDate>Mon, 26 Jan 2026 00:00:00 +0000</pubDate>
      <guid>https://ravichaganti.com/blog/building-a-multi-agent-linkedin-newsletter-system-with-google-adk/</guid>
      <description>&lt;p&gt;Google&amp;rsquo;s Agent Development Kit (ADK) provides &lt;a href=&#34;https://google.github.io/adk-docs/agents/workflow-agents/&#34;&gt;workflow agents&lt;/a&gt; to enable more deterministic agent execution. These workflows can be combined to create more complex agentic workflows.&lt;/p&gt;&#xA;&lt;p&gt;In this post, I&amp;rsquo;ll walk you through how I created an AI-powered content pipeline that:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Researches&lt;/strong&gt; trending topics using Google Search&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Writes&lt;/strong&gt; engaging newsletter drafts&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Edits&lt;/strong&gt; and quality-checks the content&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Publishes&lt;/strong&gt; the final version to a local file&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;Let&amp;rsquo;s dive in!&lt;/p&gt;&#xA;&lt;h3 id=&#34;the-big-picture-a-team-of-specialized-agents&#34;&gt;The Big Picture: A Team of Specialized Agents&lt;/h3&gt;&#xA;&lt;p&gt;Instead of building one massive AI that does everything (and probably does nothing well), I went with a &lt;strong&gt;multi-agent architecture&lt;/strong&gt;. Think of it like assembling a content team:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Google ADK - OpenAPI tools, agents-as-tools, authentication, and long-running operations</title>
      <link>https://ravichaganti.com/blog/google-adk-openapi-tools-agents-as-tools-authentication-and-long-running-operations/</link>
      <pubDate>Tue, 23 Dec 2025 00:00:00 +0000</pubDate>
      <guid>https://ravichaganti.com/blog/google-adk-openapi-tools-agents-as-tools-authentication-and-long-running-operations/</guid>
      <description>&lt;p&gt;Imagine this scenario. Your company has dozens of internal REST APIs, each with an OpenAPI specification already published. You need an agent that can query the inventory service, place orders through the fulfillment API, and check shipment tracking, all without writing individual tool functions for every single endpoint. Now layer on some more complexity. Some of those APIs require OAuth2 tokens. One task, say generating a compliance report, takes ten minutes to complete. And you want a coordinator agent that can delegate research tasks to a specialized sub-agent without losing control of the conversation.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Google ADK - MCP tools</title>
      <link>https://ravichaganti.com/blog/google-adk-mcp-tools/</link>
      <pubDate>Sat, 20 Dec 2025 00:00:00 +0000</pubDate>
      <guid>https://ravichaganti.com/blog/google-adk-mcp-tools/</guid>
      <description>&lt;p&gt;Consider you are building an agent that needs to interact with a company&amp;rsquo;s database, pull data from a third-party API, and read files from a shared drive. Without a standard protocol, you would end up writing custom integration code for each backend. Every new tool means a new adapter. Every new agent that needs the same tool means duplicating that adapter. This approach does not scale. The Model Context Protocol (MCP) solves this by providing a universal standard for how agents connect to external tools and data sources. With MCP, a tool is built once, and any MCP-compatible agent can discover and use it. Google ADK has first-class support for MCP, enabling your agents to both consume tools from MCP servers and expose their own tools as MCP servers.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Google ADK - Runner and execution architecture</title>
      <link>https://ravichaganti.com/blog/google-adk-runner-and-execution-architecture/</link>
      <pubDate>Thu, 18 Dec 2025 00:00:00 +0000</pubDate>
      <guid>https://ravichaganti.com/blog/google-adk-runner-and-execution-architecture/</guid>
      <description>&lt;p&gt;You have defined your agents, wired up tools, set up callbacks, and configured sessions with scoped state. But when a user sends a message, what actually happens? Who calls the agent? Who persists in the state changes? Who decides when the conversation turn is over? The answer to all of these is the &lt;code&gt;Runner&lt;/code&gt;. The Runner is the central orchestrator of the ADK runtime. It receives a user&amp;rsquo;s query, starts the agent, processes every event the agent emits, commits state changes via the &lt;code&gt;SessionService&lt;/code&gt;, and forwards events to the caller. Without the Runner, your agents, tools, and callbacks are just definitions sitting idle. The &lt;code&gt;Runner&lt;/code&gt; is the engine that brings them to life.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Google ADK - Callbacks</title>
      <link>https://ravichaganti.com/blog/google-adk-callbacks/</link>
      <pubDate>Fri, 12 Dec 2025 00:00:00 +0000</pubDate>
      <guid>https://ravichaganti.com/blog/google-adk-callbacks/</guid>
      <description>&lt;p&gt;Imagine you built a customer support agent. It works well, but you then discover that the LLM occasionally leaks email addresses in its responses. You need to sanitize output before the user sees it. Or consider a flight booking agent where only admin users should be allowed to cancel reservations. You need to check permissions before a tool executes. Or maybe the same question is asked a hundred times a day, and each time you are paying for an LLM API call. You need to return cached responses and skip the model entirely. All of these share a common pattern. You need to run your code at specific points in the agent&amp;rsquo;s execution pipeline, before or after the model call, before or after a tool runs, before or after the agent itself. This is where the callbacks feature comes into play.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Google ADK - Sessions, state, and memory</title>
      <link>https://ravichaganti.com/blog/google-adk-sessions-state-and-memory/</link>
      <pubDate>Fri, 05 Dec 2025 00:00:00 +0000</pubDate>
      <guid>https://ravichaganti.com/blog/google-adk-sessions-state-and-memory/</guid>
      <description>&lt;p&gt;Imagine you built a travel-booking agent. A user says, &amp;ldquo;Find flights to Paris, and the agent returns options. Then the user says, &amp;ldquo;Book the second one.&amp;rdquo; Without any memory of the previous turn, the agent has no idea what &amp;ldquo;the second one&amp;rdquo; refers to. The conversation is dead. This is the fundamental problem with LLMs. LLMs are stateless. Every API call to an LLM is independent. The model does not inherently remember what was said before. Yet meaningful conversations are inherently multi-turn, contextual, and stateful. This is where agent memory comes into play. Agent memory is the system built around the LLM to allow it to retain information, learn from past interactions, and maintain continuity within and across conversations.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Google ADK - types of agents</title>
      <link>https://ravichaganti.com/blog/google-adk-types-of-agents/</link>
      <pubDate>Wed, 03 Dec 2025 00:00:00 +0000</pubDate>
      <guid>https://ravichaganti.com/blog/google-adk-types-of-agents/</guid>
      <description>&lt;p&gt;In the introduction to Google ADK, we looked at the basics of using ADK to create an agent, connect tools, and also learnt how to define agents using the declarative YAML configuration. The example we implemented used the &lt;code&gt;Agent&lt;/code&gt; class. This class is an alias of the &lt;code&gt;LlmAgent&lt;/code&gt; class. &lt;code&gt;LlmAgent&lt;/code&gt; behavior is non-deterministic as it uses an LLM for deciding what tools to use or how to proceed toward a goal. ADK also offers &lt;a href=&#34;https://google.github.io/adk-docs/agents/workflow-agents/&#34;&gt;workflow agents&lt;/a&gt; that are more deterministic, control the execution flow of their sub-agents, and operate according to predefined logic. The execution flow of workflow agents depends on their type.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Introduction to Google Agent Development Kit</title>
      <link>https://ravichaganti.com/blog/introduction-to-google-agent-development-kit/</link>
      <pubDate>Mon, 01 Dec 2025 00:00:00 +0000</pubDate>
      <guid>https://ravichaganti.com/blog/introduction-to-google-agent-development-kit/</guid>
      <description>&lt;p&gt;Every other week, we see a new framework claiming to simplifythe  development of AI agents. Thanks to the growing interest in agentic AI. Earlier this year, Google released its framework for developing agents, which it called the Agent Development Kit (ADK).&lt;/p&gt;&#xA;&lt;div class=&#34;youtube-embed&#34; style=&#34;max-width: 100%; margin: 1.5rem auto;&#34;&gt;&#xA;  &#xA;  &lt;div id=&#34;youtube-2d93e79017b3ec8606e6135d3548ef28-placeholder&#34; class=&#34;youtube-placeholder hidden&#34;&gt;&#xA;    &lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden; border-radius: 0.5rem; background: linear-gradient(135deg, #1a1a1a 0%, #2d2d2d 100%);&#34;&gt;&#xA;      &lt;div style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; display: flex; flex-direction: column; align-items: center; justify-content: center; padding: 2rem; text-align: center;&#34;&gt;&#xA;        &#xA;        &lt;svg style=&#34;width: 4rem; height: 4rem; margin-bottom: 1rem; opacity: 0.9;&#34; viewBox=&#34;0 0 24 24&#34; fill=&#34;#FF0000&#34;&gt;&#xA;          &lt;path d=&#34;M23.498 6.186a3.016 3.016 0 0 0-2.122-2.136C19.505 3.545 12 3.545 12 3.545s-7.505 0-9.377.505A3.017 3.017 0 0 0 .502 6.186C0 8.07 0 12 0 12s0 3.93.502 5.814a3.016 3.016 0 0 0 2.122 2.136c1.871.505 9.376.505 9.376.505s7.505 0 9.377-.505a3.015 3.015 0 0 0 2.122-2.136C24 15.93 24 12 24 12s0-3.93-.502-5.814zM9.545 15.568V8.432L15.818 12l-6.273 3.568z&#34;/&gt;&#xA;        &lt;/svg&gt;&#xA;&#xA;        &lt;h4 style=&#34;color: #ffffff; font-size: 1.125rem; font-weight: 600; margin-bottom: 0.5rem;&#34;&gt;&#xA;          YouTube Video&#xA;        &lt;/h4&gt;&#xA;        &lt;p style=&#34;color: #cccccc; font-size: 0.875rem; margin-bottom: 1.5rem; max-width: 400px;&#34;&gt;&#xA;          This video requires your consent to load content from YouTube, which may set tracking cookies.&#xA;        &lt;/p&gt;</description>
    </item>
  </channel>
</rss>
