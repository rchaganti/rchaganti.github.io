<!DOCTYPE html>
<html lang="en-us">
<head>
  
  <script>
    (function() {
      const stored = localStorage.getItem('theme-preference');
      const prefersDark = window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches;
      const theme = stored || (prefersDark ? 'dark' : 'light');

      if (theme === 'dark') {
        document.documentElement.classList.add('dark');
      }
    })();
  </script>

  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">

  
  <title>Local model serving - Using Foundry Local | Ravikanth Chaganti</title>

  
  <meta name="description" content="In this series of articles on local model serving, we learned about using Ollama, Docker Model Runner, and LMStudio. At Build 2025, Microsoft announced Foundry Local. This is specifically designed for running AI models on resource-constrained devices, making it ideal for local AI inference on edge devices. Foundry Local features model management and deployment via a command-line interface, and offers an OpenAI API-compatible RESTful API. It also supports Python, C#, Rust, and JavaScript SDKs for local AI model management.">
  <meta name="author" content="Ravikanth Chaganti">

  
  <meta property="og:title" content="Local model serving - Using Foundry Local">
  <meta property="og:description" content="In this series of articles on local model serving, we learned about using Ollama, Docker Model Runner, and LMStudio. At Build 2025, Microsoft announced Foundry Local. This is specifically designed for running AI models on resource-constrained devices, making it ideal for local AI inference on edge devices. Foundry Local features model management and deployment via a command-line interface, and offers an OpenAI API-compatible RESTful API. It also supports Python, C#, Rust, and JavaScript SDKs for local AI model management.">
  <meta property="og:type" content="article">
  <meta property="og:url" content="https://ravichaganti.com/blog/local-model-serving-using-foundry-local/">
  
  <meta property="og:image" content="https://ravichaganti.com/images/localllm.png">

  
  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:title" content="Local model serving - Using Foundry Local">
  <meta name="twitter:description" content="In this series of articles on local model serving, we learned about using Ollama, Docker Model Runner, and LMStudio. At Build 2025, Microsoft announced Foundry Local. This is specifically designed for running AI models on resource-constrained devices, making it ideal for local AI inference on edge devices. Foundry Local features model management and deployment via a command-line interface, and offers an OpenAI API-compatible RESTful API. It also supports Python, C#, Rust, and JavaScript SDKs for local AI model management.">
  <meta name="twitter:image" content="https://ravichaganti.com/images/localllm.png">
  <meta name="twitter:site" content="@ravikanth">

  
  <link rel="canonical" href="https://ravichaganti.com/blog/local-model-serving-using-foundry-local/">

  
  <link rel="alternate" type="application/rss+xml" href="https://ravichaganti.com/index.xml">

  
  <link rel="icon" type="image/svg+xml" href="/favicon.svg">
  <link rel="alternate icon" type="image/x-icon" href="/favicon.ico">

  
  <link rel="stylesheet" href="/css/main.css">

  
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Poppins:wght@400;500;600;700&family=JetBrains+Mono:wght@400;500;600&display=swap" rel="stylesheet">
</head>

<body class="flex flex-col min-h-screen bg-gray-50 dark:bg-dark-bg">
  <header class="sticky top-0 z-50 bg-white dark:bg-dark-bg-secondary shadow-md relative">
  <nav class="container mx-auto px-4 py-4">
    <div class="flex items-center justify-between">
      
      <div class="flex items-center">
        <a href="https://ravichaganti.com/" class="flex items-center gap-3 text-gray-900 dark:text-dark-text hover:text-primary transition-colors no-underline group">
          
          <svg width="40" height="40" viewBox="0 0 40 40" fill="none" xmlns="http://www.w3.org/2000/svg" class="flex-shrink-0">
            <circle cx="20" cy="20" r="18" stroke="currentColor" stroke-width="2" class="group-hover:stroke-primary transition-colors"/>
            <text x="20" y="26" font-family="sans-serif" font-size="16" font-weight="bold" text-anchor="middle" fill="currentColor">RC</text>
          </svg>
          
          <div class="flex flex-col leading-tight">
            <span class="text-xs sm:text-sm font-semibold">Cloud Native</span>
            <span class="text-xs sm:text-sm font-semibold">Agentic AI</span>
            <span class="text-xs sm:text-sm font-semibold">Infrastructure</span>
          </div>
        </a>
      </div>

      
      <div class="hidden md:flex items-center space-x-8">
        
          <a href="/blog/" class="text-gray-700 dark:text-dark-text-secondary hover:text-primary font-medium transition-all no-underline hover:underline hover:decoration-blue-500 hover:decoration-2 hover:underline-offset-4">
            Blog
          </a>
        
          <a href="/books/" class="text-gray-700 dark:text-dark-text-secondary hover:text-primary font-medium transition-all no-underline hover:underline hover:decoration-blue-500 hover:decoration-2 hover:underline-offset-4">
            Books
          </a>
        
          <a href="/slides/" class="text-gray-700 dark:text-dark-text-secondary hover:text-primary font-medium transition-all no-underline hover:underline hover:decoration-blue-500 hover:decoration-2 hover:underline-offset-4">
            Slides
          </a>
        
          <a href="/videos/" class="text-gray-700 dark:text-dark-text-secondary hover:text-primary font-medium transition-all no-underline hover:underline hover:decoration-blue-500 hover:decoration-2 hover:underline-offset-4">
            Videos
          </a>
        
          <a href="/about/" class="text-gray-700 dark:text-dark-text-secondary hover:text-primary font-medium transition-all no-underline hover:underline hover:decoration-blue-500 hover:decoration-2 hover:underline-offset-4">
            About
          </a>
        
      </div>

      
      <div class="hidden md:flex items-center space-x-4" id="social-search-container">
        
        <div id="social-icons" class="flex items-center space-x-3">
          

<a href="https://twitter.com/ravikanth" target="_blank" rel="noopener noreferrer" class="p-2 hover:bg-gray-100 dark:hover:bg-dark-bg-tertiary rounded-full transition-colors" aria-label="Twitter">
  <svg class="w-5 h-5 text-gray-700 dark:text-dark-text hover:text-primary dark:hover:text-blue-400" fill="currentColor" viewBox="0 0 24 24">
    <path d="M23.953 4.57a10 10 0 01-2.825.775 4.958 4.958 0 002.163-2.723c-.951.555-2.005.959-3.127 1.184a4.92 4.92 0 00-8.384 4.482C7.69 8.095 4.067 6.13 1.64 3.162a4.822 4.822 0 00-.666 2.475c0 1.71.87 3.213 2.188 4.096a4.904 4.904 0 01-2.228-.616v.06a4.923 4.923 0 003.946 4.827 4.996 4.996 0 01-2.212.085 4.936 4.936 0 004.604 3.417 9.867 9.867 0 01-6.102 2.105c-.39 0-.779-.023-1.17-.067a13.995 13.995 0 007.557 2.209c9.053 0 13.998-7.496 13.998-13.985 0-.21 0-.42-.015-.63A9.935 9.935 0 0024 4.59z"/>
  </svg>
</a>



<a href="https://github.com/rchaganti" target="_blank" rel="noopener noreferrer" class="p-2 hover:bg-gray-100 dark:hover:bg-dark-bg-tertiary rounded-full transition-colors" aria-label="GitHub">
  <svg class="w-5 h-5 text-gray-700 dark:text-dark-text hover:text-primary dark:hover:text-blue-400" fill="currentColor" viewBox="0 0 24 24">
    <path fill-rule="evenodd" d="M12 2C6.477 2 2 6.484 2 12.017c0 4.425 2.865 8.18 6.839 9.504.5.092.682-.217.682-.483 0-.237-.008-.868-.013-1.703-2.782.605-3.369-1.343-3.369-1.343-.454-1.158-1.11-1.466-1.11-1.466-.908-.62.069-.608.069-.608 1.003.07 1.531 1.032 1.531 1.032.892 1.53 2.341 1.088 2.91.832.092-.647.35-1.088.636-1.338-2.22-.253-4.555-1.113-4.555-4.951 0-1.093.39-1.988 1.029-2.688-.103-.253-.446-1.272.098-2.65 0 0 .84-.27 2.75 1.026A9.564 9.564 0 0112 6.844c.85.004 1.705.115 2.504.337 1.909-1.296 2.747-1.027 2.747-1.027.546 1.379.202 2.398.1 2.651.64.7 1.028 1.595 1.028 2.688 0 3.848-2.339 4.695-4.566 4.943.359.309.678.92.678 1.855 0 1.338-.012 2.419-.012 2.747 0 .268.18.58.688.482A10.019 10.019 0 0022 12.017C22 6.484 17.522 2 12 2z" clip-rule="evenodd"/>
  </svg>
</a>



<a href="https://linkedin.com/in/rchaganti" target="_blank" rel="noopener noreferrer" class="p-2 hover:bg-gray-100 dark:hover:bg-dark-bg-tertiary rounded-full transition-colors" aria-label="LinkedIn">
  <svg class="w-5 h-5 text-gray-700 dark:text-dark-text hover:text-primary dark:hover:text-blue-400" fill="currentColor" viewBox="0 0 24 24">
    <path d="M20.447 20.452h-3.554v-5.569c0-1.328-.027-3.037-1.852-3.037-1.853 0-2.136 1.445-2.136 2.939v5.667H9.351V9h3.414v1.561h.046c.477-.9 1.637-1.85 3.37-1.85 3.601 0 4.267 2.37 4.267 5.455v6.286zM5.337 7.433c-1.144 0-2.063-.926-2.063-2.065 0-1.138.92-2.063 2.063-2.063 1.14 0 2.064.925 2.064 2.063 0 1.139-.925 2.065-2.064 2.065zm1.782 13.019H3.555V9h3.564v11.452zM22.225 0H1.771C.792 0 0 .774 0 1.729v20.542C0 23.227.792 24 1.771 24h20.451C23.2 24 24 23.227 24 22.271V1.729C24 .774 23.2 0 22.222 0h.003z"/>
  </svg>
</a>




        </div>

        
        <button
          id="theme-toggle"
          class="p-2 hover:bg-gray-100 dark:hover:bg-dark-bg-tertiary rounded-full transition-colors"
          aria-label="Toggle dark mode"
          title="Toggle dark mode"
        >
          
          <svg class="theme-icon-sun w-5 h-5 text-gray-700 dark:text-dark-text hidden" fill="none" stroke="currentColor" viewBox="0 0 24 24">
            <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M12 3v1m0 16v1m9-9h-1M4 12H3m15.364 6.364l-.707-.707M6.343 6.343l-.707-.707m12.728 0l-.707.707M6.343 17.657l-.707.707M16 12a4 4 0 11-8 0 4 4 0 018 0z"></path>
          </svg>

          
          <svg class="theme-icon-moon w-5 h-5 text-gray-700 dark:text-dark-text" fill="none" stroke="currentColor" viewBox="0 0 24 24">
            <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M20.354 15.354A9 9 0 018.646 3.646 9.003 9.003 0 0012 21a9.003 9.003 0 008.354-5.646z"></path>
          </svg>
        </button>

        
        <button id="search-toggle" class="p-2 hover:bg-gray-100 dark:hover:bg-dark-bg-tertiary rounded-full transition-colors" aria-label="Search">
          <svg class="w-5 h-5 text-gray-700 dark:text-dark-text" fill="none" stroke="currentColor" viewBox="0 0 24 24">
            <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M21 21l-6-6m2-5a7 7 0 11-14 0 7 7 0 0114 0z"></path>
          </svg>
        </button>

        
        <div id="search-box" class="hidden">
          
<div class="relative">
  <input
    type="text"
    id="search-input"
    placeholder="Search articles..."
    class="w-64 px-4 py-2 text-sm border border-gray-300 dark:border-dark-border bg-white dark:bg-dark-bg-secondary text-gray-900 dark:text-dark-text rounded-lg focus:outline-none focus:ring-2 focus:ring-primary"
    aria-label="Search"
    autocomplete="off"
  >
  <div id="search-results" class="absolute top-full mt-2 w-96 bg-white dark:bg-dark-bg-secondary border border-gray-200 dark:border-dark-border rounded-lg shadow-xl hidden max-h-96 overflow-y-auto z-50">
    
  </div>
</div>


<script src="https://cdn.jsdelivr.net/npm/fuse.js@7.0.0"></script>


<script>
(function() {
  let headerFuse;
  let headerSearchData = [];

  
  fetch('/index.json')
    .then(response => response.json())
    .then(data => {
      headerSearchData = data;

      
      const options = {
        keys: [
          { name: 'title', weight: 3 },
          { name: 'excerpt', weight: 2 },
          { name: 'content', weight: 1 },
          { name: 'categories', weight: 1.5 },
          { name: 'series', weight: 1.5 }
        ],
        threshold: 0.4,
        includeScore: true,
        ignoreLocation: true,
        minMatchCharLength: 2
      };

      headerFuse = new Fuse(headerSearchData, options);
    })
    .catch(error => console.error('Error loading search index:', error));

  
  const searchInput = document.getElementById('search-input');
  const searchResults = document.getElementById('search-results');

  if (searchInput && searchResults) {
    searchInput.addEventListener('input', function(e) {
      const query = e.target.value.trim();

      if (query.length < 2) {
        searchResults.classList.add('hidden');
        return;
      }

      
      const results = headerFuse.search(query);

      
      if (results.length === 0) {
        searchResults.innerHTML = '<div class="p-4 text-center text-gray-500 text-sm">No results found</div>';
        searchResults.classList.remove('hidden');
        return;
      }

      searchResults.innerHTML = results.slice(0, 5).map(result => {
        const item = result.item;
        const date = new Date(item.date).toLocaleDateString('en-US', { month: 'short', day: 'numeric', year: 'numeric' });

        return `
          <a href="${item.permalink}" class="block p-3 hover:bg-gray-50 border-b border-gray-100 last:border-b-0 no-underline">
            <div class="font-medium text-sm text-gray-900 mb-1">${item.title}</div>
            <div class="flex items-center gap-2 mb-1">
              <span class="text-xs text-gray-500">${date}</span>
              ${item.categories ? item.categories.slice(0, 2).map(cat => `
                <span class="inline-block px-1.5 py-0.5 text-xs rounded" style="background-color: rgba(30, 64, 175, 0.1); color: #1e40af;">
                  ${cat}
                </span>
              `).join('') : ''}
            </div>
            ${item.excerpt ? `<p class="text-xs text-gray-600 line-clamp-2">${item.excerpt}</p>` : ''}
          </a>
        `;
      }).join('');

      searchResults.classList.remove('hidden');
    });

    
    document.addEventListener('click', function(e) {
      if (!searchInput.contains(e.target) && !searchResults.contains(e.target)) {
        searchResults.classList.add('hidden');
      }
    });

    
    searchInput.addEventListener('keydown', function(e) {
      if (e.key === 'Escape') {
        searchResults.classList.add('hidden');
        searchInput.blur();
      }
    });
  }
})();
</script>

        </div>
      </div>

      
      <button id="mobile-menu-toggle" class="md:hidden p-2 hover:bg-gray-100 rounded" aria-label="Menu">
        <svg class="w-6 h-6" fill="none" stroke="currentColor" viewBox="0 0 24 24">
          <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M4 6h16M4 12h16M4 18h16"></path>
        </svg>
      </button>
    </div>

    
    <div id="mobile-menu" class="hidden md:hidden mt-4 pb-4">
      
        <a href="/blog/" class="block py-3 px-2 text-base text-gray-700 dark:text-dark-text-secondary hover:text-primary hover:bg-gray-100 dark:hover:bg-dark-bg-tertiary transition-colors no-underline rounded-md min-h-[44px] flex items-center">
          Blog
        </a>
      
        <a href="/books/" class="block py-3 px-2 text-base text-gray-700 dark:text-dark-text-secondary hover:text-primary hover:bg-gray-100 dark:hover:bg-dark-bg-tertiary transition-colors no-underline rounded-md min-h-[44px] flex items-center">
          Books
        </a>
      
        <a href="/slides/" class="block py-3 px-2 text-base text-gray-700 dark:text-dark-text-secondary hover:text-primary hover:bg-gray-100 dark:hover:bg-dark-bg-tertiary transition-colors no-underline rounded-md min-h-[44px] flex items-center">
          Slides
        </a>
      
        <a href="/videos/" class="block py-3 px-2 text-base text-gray-700 dark:text-dark-text-secondary hover:text-primary hover:bg-gray-100 dark:hover:bg-dark-bg-tertiary transition-colors no-underline rounded-md min-h-[44px] flex items-center">
          Videos
        </a>
      
        <a href="/about/" class="block py-3 px-2 text-base text-gray-700 dark:text-dark-text-secondary hover:text-primary hover:bg-gray-100 dark:hover:bg-dark-bg-tertiary transition-colors no-underline rounded-md min-h-[44px] flex items-center">
          About
        </a>
      
    </div>
  </nav>

  
  
    <div id="reading-progress" class="absolute bottom-0 left-0 w-full h-1 bg-primary transition-all duration-200 z-10" style="width: 0%; max-width: 100%;"></div>
  
</header>


<script>
  document.getElementById('mobile-menu-toggle')?.addEventListener('click', function() {
    const menu = document.getElementById('mobile-menu');
    menu?.classList.toggle('hidden');
  });

  document.getElementById('search-toggle')?.addEventListener('click', function() {
    const socialIcons = document.getElementById('social-icons');
    const searchBox = document.getElementById('search-box');
    socialIcons?.classList.toggle('hidden');
    searchBox?.classList.toggle('hidden');
  });
</script>


  <main class="flex-grow">
    
<article class="container mx-auto px-4 sm:px-6 md:px-4 py-8 sm:py-10 md:py-12">
  <div class="max-w-4xl mx-auto">
    
    <header class="mb-8">
      
      <nav class="text-xs sm:text-sm mb-4">
        <ol class="flex items-center space-x-2 text-gray-600 dark:text-dark-text-secondary">
          <li><a href="https://ravichaganti.com/" class="hover:text-primary dark:hover:text-blue-400">Home</a></li>
          <li><span class="mx-2">/</span></li>
          <li><a href="/blog/" class="hover:text-primary dark:hover:text-blue-400">Blog</a></li>
          
            <li><span class="mx-2">/</span></li>
            <li><a href="/categories/inferencing/" class="hover:text-primary dark:hover:text-blue-400">inferencing</a></li>
          
        </ol>
      </nav>

      
      <div class="flex flex-wrap items-center gap-2 sm:gap-3 md:gap-4 text-sm sm:text-base text-gray-600 dark:text-dark-text-secondary mb-6">
        
        <div class="flex items-center">
          <svg class="w-4 h-4 sm:w-5 sm:h-5 mr-2" fill="none" stroke="currentColor" viewBox="0 0 24 24">
            <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M8 7V3m8 4V3m-9 8h10M5 21h14a2 2 0 002-2V7a2 2 0 00-2-2H5a2 2 0 00-2 2v12a2 2 0 002 2z"></path>
          </svg>
          <time datetime="2025-07-17">July 17, 2025</time>
        </div>

        
        
          <span>â€¢</span>
          <div class="flex items-center">
            <svg class="w-4 h-4 sm:w-5 sm:h-5 mr-2" fill="none" stroke="currentColor" viewBox="0 0 24 24">
              <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M12 8v4l3 3m6-3a9 9 0 11-18 0 9 9 0 0118 0z"></path>
            </svg>
            <span>5 min read</span>
          </div>
        

        
        
      </div>

      
      <div class="flex flex-wrap gap-2 mb-6">
        
          
            <a href="/categories/inferencing/" class="inline-block px-3 py-1 text-sm font-medium bg-primary/10 dark:bg-primary/20 text-primary dark:text-blue-400 rounded-full hover:bg-primary/20 dark:hover:bg-primary/30 transition-colors no-underline">
              inferencing
            </a>
          
            <a href="/categories/local-serving/" class="inline-block px-3 py-1 text-sm font-medium bg-primary/10 dark:bg-primary/20 text-primary dark:text-blue-400 rounded-full hover:bg-primary/20 dark:hover:bg-primary/30 transition-colors no-underline">
              local serving
            </a>
          
        
        
          
            <a href="/series/local-llm-serving/" class="inline-block px-3 py-1 text-sm font-medium bg-secondary/10 dark:bg-secondary/20 text-secondary dark:text-purple-400 rounded-full hover:bg-secondary/20 dark:hover:bg-secondary/30 transition-colors no-underline">
              ðŸ“š Series: Local LLM Serving
            </a>
          
        
      </div>

      
      <div class="mb-6 sm:mb-8 rounded-lg overflow-hidden shadow-lg">
        
        <img src="/images/localllm.png" alt="Local model serving - Using Foundry Local" class="w-full h-auto max-h-64 sm:max-h-96 md:max-h-none object-cover">
      </div>

      
      
        <div class="text-base sm:text-lg md:text-xl text-gray-700 dark:text-dark-text-secondary italic border-l-4 border-primary dark:border-blue-400 pl-4 sm:pl-6 py-2 mb-6 sm:mb-8 bg-gray-50 dark:bg-dark-bg-tertiary rounded-r">
          There are several options available for running Large Language Model (LLM) inference locally. Foundry Local by Microsoft is a new entrant.
        </div>
      
    </header>

    
    


  
  
  
    <aside class="bg-gradient-to-br from-secondary/5 to-primary/5 dark:from-secondary/10 dark:to-primary/10 rounded-lg shadow-md dark:shadow-2xl dark:shadow-black/20 p-4 mb-6 border border-secondary/20 dark:border-secondary/30">
      
      <button
        class="flex items-center justify-between w-full text-left font-semibold text-base text-gray-900 dark:text-dark-text hover:text-secondary dark:hover:text-purple-400 transition-colors"
        aria-expanded="false"
        aria-controls="series-content"
      >
        <span class="flex items-center">
          <svg class="w-4 h-4 mr-2" fill="none" stroke="currentColor" viewBox="0 0 24 24">
            <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M12 6.253v13m0-13C10.832 5.477 9.246 5 7.5 5S4.168 5.477 3 6.253v13C4.168 18.477 5.754 18 7.5 18s3.332.477 4.5 1.253m0-13C13.168 5.477 14.754 5 16.5 5c1.747 0 3.332.477 4.5 1.253v13C19.832 18.477 18.247 18 16.5 18c-1.746 0-3.332.477-4.5 1.253"></path>
          </svg>
          Series: Local LLM Serving
        </span>
        <svg
          id="series-chevron"
          class="w-4 h-4 transform transition-transform -rotate-90"
          fill="none"
          stroke="currentColor"
          viewBox="0 0 24 24"
        >
          <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 9l-7 7-7-7"></path>
        </svg>
      </button>

      
      <p class="text-xs text-gray-600 dark:text-dark-text-secondary mt-2 mb-2 collapsed" id="series-description">
        Part of a 4-part series
      </p>

      
      <nav id="series-content" class="series-content collapsed mt-1">
        <ol class="space-y-3">
          
            <li class="flex items-start">
              <span class="flex-shrink-0 w-6 h-6 rounded-full bg-secondary/20 dark:bg-secondary/30 text-secondary dark:text-purple-400 flex items-center justify-center text-xs font-bold mr-3 mt-0.5">
                1
              </span>
              <div class="flex-grow">
                
                  <a href="https://ravichaganti.com/blog/local-model-serving-using-ollama/" class="text-gray-700 dark:text-dark-text-secondary hover:text-secondary dark:hover:text-purple-400 transition-colors no-underline hover:underline">
                    Local model serving - Using Ollama
                  </a>
                
                <p class="text-xs text-gray-500 dark:text-dark-text-muted mt-1">Jul 14, 2025</p>
              </div>
            </li>
          
            <li class="flex items-start">
              <span class="flex-shrink-0 w-6 h-6 rounded-full bg-secondary/20 dark:bg-secondary/30 text-secondary dark:text-purple-400 flex items-center justify-center text-xs font-bold mr-3 mt-0.5">
                2
              </span>
              <div class="flex-grow">
                
                  <a href="https://ravichaganti.com/blog/local-model-serving-using-lm-studio/" class="text-gray-700 dark:text-dark-text-secondary hover:text-secondary dark:hover:text-purple-400 transition-colors no-underline hover:underline">
                    Local model serving - Using LM Studio
                  </a>
                
                <p class="text-xs text-gray-500 dark:text-dark-text-muted mt-1">Jul 15, 2025</p>
              </div>
            </li>
          
            <li class="flex items-start">
              <span class="flex-shrink-0 w-6 h-6 rounded-full bg-secondary/20 dark:bg-secondary/30 text-secondary dark:text-purple-400 flex items-center justify-center text-xs font-bold mr-3 mt-0.5">
                3
              </span>
              <div class="flex-grow">
                
                  <a href="https://ravichaganti.com/blog/local-model-serving-using-docker-model-runner/" class="text-gray-700 dark:text-dark-text-secondary hover:text-secondary dark:hover:text-purple-400 transition-colors no-underline hover:underline">
                    Local model serving - Using Docker model runner
                  </a>
                
                <p class="text-xs text-gray-500 dark:text-dark-text-muted mt-1">Jul 16, 2025</p>
              </div>
            </li>
          
            <li class="flex items-start">
              <span class="flex-shrink-0 w-6 h-6 rounded-full bg-secondary/20 dark:bg-secondary/30 text-secondary dark:text-purple-400 flex items-center justify-center text-xs font-bold mr-3 mt-0.5">
                4
              </span>
              <div class="flex-grow">
                
                  <span class="font-bold text-secondary dark:text-purple-400">
                    Local model serving - Using Foundry Local
                    <span class="text-xs ml-2 px-2 py-0.5 bg-secondary dark:bg-purple-600 text-white rounded">You are here</span>
                  </span>
                
                <p class="text-xs text-gray-500 dark:text-dark-text-muted mt-1">Jul 17, 2025</p>
              </div>
            </li>
          
        </ol>

        
        <div class="mt-6 pt-6 border-t border-secondary/20 dark:border-secondary/30 grid grid-cols-2 gap-4">
          
          
            
          
            
          
            
          
            
              
            
          

          
          
            
            <a href="https://ravichaganti.com/blog/local-model-serving-using-docker-model-runner/" class="flex items-center text-sm text-gray-700 dark:text-dark-text-secondary hover:text-secondary dark:hover:text-purple-400 transition-colors no-underline group">
              <svg class="w-4 h-4 mr-1 group-hover:-translate-x-1 transition-transform" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M15 19l-7-7 7-7"></path>
              </svg>
              <span class="truncate">Local model serving - Using Docker model runner</span>
            </a>
          

          
          
        </div>
      </nav>
    </aside>
  



    
    



    
    <div class="prose prose-sm sm:prose-base md:prose-lg max-w-none mb-8 sm:mb-10 md:mb-12">
      <p>In this series of articles on local model serving, we learned about using <a href="https://ai-engineer.in/post/local-model-serving-using-ollama/">Ollama</a>, <a href="https://ai-engineer.in/post/local-model-serving-using-docker-model-runner/">Docker Model Runner</a>, and <a href="https://ai-engineer.in/post/local-model-serving-using-lmstudio/">LMStudio</a>. At Build 2025, <a href="https://devblogs.microsoft.com/foundry/foundry-local-a-new-era-of-edge-ai/">Microsoft announced Foundry Local</a>. This is specifically designed for running AI models on resource-constrained devices, making it ideal for local AI inference on edge devices. Foundry Local features model management and deployment via a <a href="https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/reference/reference-cli">command-line interface</a>, and offers an OpenAI API-compatible <a href="https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/reference/reference-rest">RESTful API</a>. It also supports Python, C#, Rust, and JavaScript <a href="https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/reference/reference-sdk">SDKs for local AI model management</a>.</p>
<h2 id="foundry-local-architecture">Foundry Local Architecture</h2>
<p>Before we delve into the details of using Foundry Local for AI inference, let&rsquo;s understand its architecture and components.</p>
<p><img src="https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/media/architecture/foundry-local-arch.png" alt="Foundry Local Architecture"></p>
<p>The <em>model management</em> component in this architecture is responsible for managing the model lifecycle, compiling models, and maintaining the model cache. The model lifecycle includes downloading, loading, running, unloading, and deleting models from the local cache.</p>
<p>The <a href="https://onnxruntime.ai/"><em>ONNX runtime</em></a> is the key component of this architecture. ONNX is a cross-platform ML model accelerator that supports models from PyTorch, JAX, and other frameworks. This runtime is responsible for executing the models and supports multiple hardware providers and device types.</p>
<p>The <em>Foundry Local service</em> is the OpenAI-compatible REST API interface for working with the inference engine. This REST API endpoint can be used with any programming language to interact with the inference endpoint. This service also provides the REST interface for model management.</p>
<p>With this brief overview of the Foundry Local architecture, let us now dive into the how!</p>
<h2 id="basics">Basics</h2>
<p>Foundry Local service needs to be installed on the local Windows or macOS system. On Windows, you can use <em>winget</em> to install Foundry Local.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl">winget install Microsoft.FoundryLocal
</span></span></code></pre></td></tr></table>
</div>
</div><p>Once the service is installed, you can use the <code>foundry service status</code> command to check its status.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl">PS C:<span class="se">\&gt;</span> foundry service status
</span></span><span class="line"><span class="cl">ðŸŸ¢ Model management service is running on http://127.0.0.1:11223/openai/status
</span></span><span class="line"><span class="cl">EP autoregistration status: Successfully downloaded and registered the following EPs: OpenVINOExecutionProvider.
</span></span><span class="line"><span class="cl">Valid EPs: CPUExecutionProvider, WebGpuExecutionProvider, OpenVINOExecutionProvider
</span></span></code></pre></td></tr></table>
</div>
</div><p>Foundry Local chooses a random port every time the service restarts. To avoid that, you can use the following command to configure a fixed port number.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl">PS C:<span class="se">\&gt;</span> foundry service <span class="nb">set</span> --port <span class="m">22334</span>
</span></span><span class="line"><span class="cl">Saving new settings
</span></span><span class="line"><span class="cl">Restarting service...
</span></span><span class="line"><span class="cl">ðŸ”´ Service is stopped.
</span></span><span class="line"><span class="cl">ðŸŸ¢ Service is Started on http://127.0.0.1:22334/, PID 14444!
</span></span></code></pre></td></tr></table>
</div>
</div><p><code>foundry cache location</code> command returns the model cache directory path.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl">PS C:<span class="se">\&gt;</span> foundry cache location
</span></span><span class="line"><span class="cl">ðŸ’¾ Cache directory path: C:<span class="se">\U</span>sers<span class="se">\r</span>avik<span class="se">\.</span>foundry<span class="se">\c</span>ache<span class="se">\m</span>odels
</span></span></code></pre></td></tr></table>
</div>
</div><p>If you want to move the model cache to a different path, you can use the <code>foundry service set --cachedir</code> command and supply the new directory path as the argument.</p>
<p>To view the existing service configuration, run the <code>foundry service set --show</code> command.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl">PS C:<span class="se">\&gt;</span> foundry service <span class="nb">set</span> --show
</span></span><span class="line"><span class="cl">No settings changed
</span></span><span class="line"><span class="cl"><span class="o">{</span>
</span></span><span class="line"><span class="cl">  <span class="s2">&#34;defaultLogLevel&#34;</span>: 2,
</span></span><span class="line"><span class="cl">  <span class="s2">&#34;serviceSettings&#34;</span>: <span class="o">{</span>
</span></span><span class="line"><span class="cl">    <span class="s2">&#34;host&#34;</span>: <span class="s2">&#34;127.0.0.1&#34;</span>,
</span></span><span class="line"><span class="cl">    <span class="s2">&#34;port&#34;</span>: 22334,
</span></span><span class="line"><span class="cl">    <span class="s2">&#34;cacheDirectoryPath&#34;</span>: <span class="s2">&#34;C:\\Users\\ravik\\.foundry\\cache\\models&#34;</span>,
</span></span><span class="line"><span class="cl">    <span class="s2">&#34;schema&#34;</span>: <span class="s2">&#34;http&#34;</span>,
</span></span><span class="line"><span class="cl">    <span class="s2">&#34;pipeName&#34;</span>: <span class="s2">&#34;inference_agent&#34;</span>,
</span></span><span class="line"><span class="cl">    <span class="s2">&#34;defaultSecondsForModelTTL&#34;</span>: 600,
</span></span><span class="line"><span class="cl">    <span class="s2">&#34;initialConnectionTimeoutInSeconds&#34;</span>: <span class="m">6</span>
</span></span><span class="line"><span class="cl">  <span class="o">}</span>
</span></span><span class="line"><span class="cl"><span class="o">}</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>To list all models available to run locally, use <code>foundry model list</code> command. This command lists all models available in the Foundry catalog</p>
<p>The <code>foundry model run</code> command runs a model for inference. This command starts an interactive session. If the model is not present in the local model cache, it gets downloaded. If you want to download the model but not run it immediately, you can use <code>foundry model download</code> command.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl">PS C:<span class="se">\&gt;</span> foundry model run phi-3.5-mini
</span></span><span class="line"><span class="cl">Model Phi-3.5-mini-instruct-openvino-gpu:1 was found in the <span class="nb">local</span> cache.
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">Interactive Chat. Enter /? or /help <span class="k">for</span> help.
</span></span><span class="line"><span class="cl">Press Ctrl+C to cancel generation. Type /exit to leave the chat.
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">Interactive mode, please enter your prompt
</span></span><span class="line"><span class="cl">&gt; In one line, What is Azure?
</span></span><span class="line"><span class="cl">ðŸ§  Thinking...
</span></span><span class="line"><span class="cl">ðŸ¤–  Azure is Microsoft<span class="err">&#39;</span>fertilized cloud computing platform offering a range of cloud services, including storage, databases, AI, and virtual machines.
</span></span></code></pre></td></tr></table>
</div>
</div><p>The <code>foundry model load</code> command loads the model from the cache for inference.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl">PS C:<span class="se">\&gt;</span> foundry model load qwen2.5-0.5b
</span></span><span class="line"><span class="cl">ðŸ•“ Loading model...
</span></span><span class="line"><span class="cl">ðŸŸ¢ Model qwen2.5-0.5b loaded successfully
</span></span></code></pre></td></tr></table>
</div>
</div><p>By default, a model loaded this way lives for only 600 seconds. To change that, you can specify the <code>--ttl</code> optional parameter. You can retrieve a list of all models using the <code>foundry service ps</code> command.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl">PS C:<span class="se">\&gt;</span> foundry service ps
</span></span><span class="line"><span class="cl">Models running in service:
</span></span><span class="line"><span class="cl">    Alias                          Model ID
</span></span><span class="line"><span class="cl">ðŸŸ¢  qwen2.5-0.5b                   qwen2.5-0.5b-instruct-openvino-gpu:2
</span></span></code></pre></td></tr></table>
</div>
</div><h2 id="inference-api">Inference API</h2>
<p>The real goal of local AI inference is to develop and use AI applications. We need to use the inference API for this. Loading a model to the foundry service enables the inference interface to the model.</p>
<p>Let us first list the loaded models using the REST API.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl">PS C:<span class="se">\&gt;</span> <span class="o">(</span>curl http://127.0.0.1:22334/v1/models<span class="o">)</span>.content
</span></span><span class="line"><span class="cl"><span class="o">{</span><span class="s2">&#34;data&#34;</span>:<span class="o">[{</span><span class="s2">&#34;vision&#34;</span>:false,<span class="s2">&#34;toolCalling&#34;</span>:false,<span class="s2">&#34;maxInputTokens&#34;</span>:114688,<span class="s2">&#34;maxOutputTokens&#34;</span>:16384,<span class="s2">&#34;id&#34;</span>:<span class="s2">&#34;Phi-3.5-mini-instruct-openvino-gpu:1&#34;</span>,<span class="s2">&#34;owned_by&#34;</span>:<span class="s2">&#34;Microsoft&#34;</span>,<span class="s2">&#34;permission&#34;</span>:<span class="o">[]</span>,<span class="s2">&#34;created&#34;</span>:1763477048,<span class="s2">&#34;CreatedTime&#34;</span>:<span class="s2">&#34;2025-11-18T14:44:08+00:00&#34;</span>,<span class="s2">&#34;IsDelta&#34;</span>:false,<span class="s2">&#34;Successful&#34;</span>:true,<span class="s2">&#34;HttpStatusCode&#34;</span>:0,<span class="s2">&#34;object&#34;</span>:<span class="s2">&#34;model&#34;</span><span class="o">}</span>,<span class="o">{</span><span class="s2">&#34;vision&#34;</span>:false,<span class="s2">&#34;toolCalling&#34;</span>:false,<span class="s2">&#34;maxInputTokens&#34;</span>:28672,<span class="s2">&#34;maxOutputTokens&#34;</span>:4096,<span class="s2">&#34;id&#34;</span>:<span class="s2">&#34;qwen2.5-0.5b-instruct-openvino-gpu:2&#34;</span>,<span class="s2">&#34;owned_by&#34;</span>:<span class="s2">&#34;Microsoft&#34;</span>,<span class="s2">&#34;permission&#34;</span>:<span class="o">[]</span>,<span class="s2">&#34;created&#34;</span>:1763466301,<span class="s2">&#34;CreatedTime&#34;</span>:<span class="s2">&#34;2025-11-18T11:45:01+00:00&#34;</span>,<span class="s2">&#34;IsDelta&#34;</span>:false,<span class="s2">&#34;Successful&#34;</span>:true,<span class="s2">&#34;HttpStatusCode&#34;</span>:0,<span class="s2">&#34;object&#34;</span>:<span class="s2">&#34;model&#34;</span><span class="o">}]</span>,<span class="s2">&#34;IsDelta&#34;</span>:false,<span class="s2">&#34;Successful&#34;</span>:true,<span class="s2">&#34;HttpStatusCode&#34;</span>:0,<span class="s2">&#34;object&#34;</span>:<span class="s2">&#34;list&#34;</span><span class="o">}</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>The <code>/v1/chat/completions</code> endpoint can be used to create a chat completion.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl">PS C:<span class="se">\&gt;</span> <span class="nv">$body</span> <span class="o">=</span> @<span class="s2">&#34;
</span></span></span><span class="line"><span class="cl"><span class="s2">&gt;&gt; {
</span></span></span><span class="line"><span class="cl"><span class="s2">&gt;&gt; &#34;</span>model<span class="s2">&#34;:&#34;</span>Phi-3.5-mini-instruct-openvino-gpu:1<span class="s2">&#34;,
</span></span></span><span class="line"><span class="cl"><span class="s2">&gt;&gt; &#34;</span>messages<span class="s2">&#34;:[
</span></span></span><span class="line"><span class="cl"><span class="s2">&gt;&gt; {
</span></span></span><span class="line"><span class="cl"><span class="s2">&gt;&gt; &#34;</span>role<span class="s2">&#34;:&#34;</span>user<span class="s2">&#34;,
</span></span></span><span class="line"><span class="cl"><span class="s2">&gt;&gt; &#34;</span>content<span class="s2">&#34;:&#34;</span>In one line, what is Azure?<span class="s2">&#34;
</span></span></span><span class="line"><span class="cl"><span class="s2">&gt;&gt; }
</span></span></span><span class="line"><span class="cl"><span class="s2">&gt;&gt; ]
</span></span></span><span class="line"><span class="cl"><span class="s2">&gt;&gt; }
</span></span></span><span class="line"><span class="cl"><span class="s2">&gt;&gt; &#34;</span>@
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">PS C:<span class="se">\&gt;</span> <span class="o">((</span>Invoke-WebRequest -Uri http://127.0.0.1:22334/v1/chat/completions -Method Post -ContentType <span class="s2">&#34;application/json&#34;</span> -Body <span class="nv">$body</span><span class="o">)</span>.content <span class="p">|</span> ConvertFrom-Json<span class="o">)</span>.Choices<span class="o">[</span>0<span class="o">]</span>.delta.content
</span></span><span class="line"><span class="cl"> Azure is Microsoft<span class="err">&#39;</span>fertility cloud computing service offering infrastructure, platforms, and services as a whole.
</span></span></code></pre></td></tr></table>
</div>
</div><p>We have got the inference working with the local model. This is a simple PowerShell command to invoke the chat completion API. You can, of course, use any OpenAI-compatible SDK in your favorite language to perform the same inference action.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">openai</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">foundry_local</span> <span class="kn">import</span> <span class="n">FoundryLocalManager</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">alias</span> <span class="o">=</span> <span class="s2">&#34;Phi-3.5-mini&#34;</span>
</span></span><span class="line"><span class="cl"><span class="n">manager</span> <span class="o">=</span> <span class="n">FoundryLocalManager</span><span class="p">(</span><span class="n">alias</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">client</span> <span class="o">=</span> <span class="n">openai</span><span class="o">.</span><span class="n">OpenAI</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">    <span class="n">base_url</span><span class="o">=</span><span class="n">manager</span><span class="o">.</span><span class="n">endpoint</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">api_key</span><span class="o">=</span><span class="n">manager</span><span class="o">.</span><span class="n">api_key</span>
</span></span><span class="line"><span class="cl"><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">response</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="n">chat</span><span class="o">.</span><span class="n">completions</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">    <span class="n">model</span><span class="o">=</span><span class="n">manager</span><span class="o">.</span><span class="n">get_model_info</span><span class="p">(</span><span class="n">alias</span><span class="p">)</span><span class="o">.</span><span class="n">id</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">messages</span><span class="o">=</span><span class="p">[{</span><span class="s2">&#34;role&#34;</span><span class="p">:</span> <span class="s2">&#34;user&#34;</span><span class="p">,</span> <span class="s2">&#34;content&#34;</span><span class="p">:</span> <span class="s2">&#34;In one line, what is Azure?&#34;</span><span class="p">}]</span>
</span></span><span class="line"><span class="cl"><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="n">response</span><span class="o">.</span><span class="n">choices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">message</span><span class="o">.</span><span class="n">content</span><span class="p">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>This is a quick overview of how Foundry Local can help with local AI inference on resource-constrained devices. In the later parts of this series, we will learn more about using Foundry Local models for different use cases.</p>
<style>
.notice-shortcode.notice-info {
  background-color: #eff6ff;
  border-color: #bfdbfe;
  color: #1e3a8a;
}
.dark .notice-shortcode.notice-info {
  background-color: rgba(30, 58, 138, 0.2);
  border-color: #1e40af;
  color: #f1f5f9;
}
.notice-shortcode.notice-warning {
  background-color: #fefce8;
  border-color: #fde047;
  color: #854d0e;
}
.dark .notice-shortcode.notice-warning {
  background-color: rgba(133, 77, 14, 0.2);
  border-color: #ca8a04;
  color: #fef9c3;
}
.notice-shortcode.notice-tip {
  background-color: #f0fdf4;
  border-color: #86efac;
  color: #14532d;
}
.dark .notice-shortcode.notice-tip {
  background-color: rgba(20, 83, 45, 0.2);
  border-color: #16a34a;
  color: #dcfce7;
}
.notice-shortcode.notice-danger {
  background-color: #fef2f2;
  border-color: #fecaca;
  color: #7f1d1d;
}
.dark .notice-shortcode.notice-danger {
  background-color: rgba(127, 29, 29, 0.2);
  border-color: #dc2626;
  color: #fecaca;
}
.notice-shortcode.notice-success {
  background-color: #ecfdf5;
  border-color: #6ee7b7;
  color: #064e3b;
}
.dark .notice-shortcode.notice-success {
  background-color: rgba(6, 78, 59, 0.2);
  border-color: #059669;
  color: #d1fae5;
}
</style>

<div class="notice-shortcode notice-info my-6 p-4 border-l-4 rounded-r-lg">
  <div class="flex items-start gap-3">
    <span class="text-2xl flex-shrink-0" style="line-height: 1;">â„¹ï¸</span>
    <div class="flex-1 notice-content">
      Last updated: 18th November 2025
    </div>
  </div>
</div>


    </div>

    
    

    
    



    
    
<nav class="mt-12 pt-8 border-t border-gray-200 dark:border-dark-border" aria-label="Post navigation">
  
  
  
  

  
  
  
    
    
    

    
    
    

    
    
    
      
    
      
    
      
    
      
        
      
    

    
    
      
        
        
      
      
    
  

  
  <div class="grid grid-cols-1 md:grid-cols-2 gap-4">
    
    <div class="flex">
      
        <a href="https://ravichaganti.com/blog/local-model-serving-using-docker-model-runner/"
           class="flex-1 group card hover:shadow-xl transition-all hover:scale-[1.02] no-underline"
           aria-label="Previous in Local LLM Serving: Local model serving - Using Docker model runner">
          <div class="flex items-start gap-3">
            
            <div class="flex-shrink-0 text-primary dark:text-blue-400 group-hover:text-secondary dark:group-hover:text-purple-400 transition-colors mt-1">
              <svg class="w-6 h-6" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M15 19l-7-7 7-7"></path>
              </svg>
            </div>

            
            <div class="flex-1 min-w-0">
              <p class="text-xs text-gray-500 dark:text-dark-text-muted mb-1 uppercase tracking-wide">Previous in Local LLM Serving</p>
              <h3 class="text-base font-bold text-gray-900 dark:text-dark-text mb-2 group-hover:text-primary dark:group-hover:text-blue-400 transition-colors">
                Local model serving - Using Docker model runner
              </h3>
              
                <p class="text-sm text-gray-600 dark:text-dark-text-secondary line-clamp-2">Docker Model Runner â€” a faster, simpler way to run and test AI models locally, right from your existing workflow. Whether youâ€™re experimenting with the latest LLMs or deploying to production, Model Runner brings the performance and control you need, without the friction.</p>
              
            </div>
          </div>
        </a>
      
    </div>

    
    <div class="flex">
      
        
        <div class="flex-1 card bg-gray-50 dark:bg-dark-bg-tertiary opacity-50 cursor-not-allowed">
          <div class="flex items-start gap-3">
            <div class="flex-1 text-right md:text-left">
              <p class="text-xs text-gray-400 dark:text-dark-text-muted mb-1 uppercase tracking-wide">No Next Article</p>
              <p class="text-sm text-gray-400 dark:text-dark-text-muted">This is the latest post</p>
            </div>
            <div class="flex-shrink-0 text-gray-400 dark:text-dark-text-muted mt-1">
              <svg class="w-6 h-6" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 5l7 7-7 7"></path>
              </svg>
            </div>
          </div>
        </div>
      
    </div>
  </div>
</nav>


    
    

    
    

    
    
  </div>

  
  <script src="/js/collapse.js"></script>
  <script src="/js/code-copy.js"></script>
</article>

  </main>

  <footer class="bg-gray-900 dark:bg-dark-bg text-gray-300 dark:text-dark-text-secondary mt-16">
  <div class="container mx-auto px-4 py-8">
    <div class="text-center text-sm">
      <p>&copy; 2026 Ravikanth Chaganti. All rights reserved.</p>
    </div>
  </div>
</footer>


  
  <button id="back-to-top"
          class="fixed bottom-8 right-8 w-12 h-12 bg-primary text-white rounded-full shadow-lg hover:bg-blue-700 transition-all opacity-0 pointer-events-none z-40"
          aria-label="Back to top"
          title="Back to top">
    <svg class="w-6 h-6 mx-auto" fill="none" stroke="currentColor" viewBox="0 0 24 24">
      <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M5 10l7-7m0 0l7 7m-7-7v18"></path>
    </svg>
  </button>

  
  

  
  <script>
    
    
    
  </script>

  
  
    <script src="/js/reading-progress.js"></script>
  

  
  <script src="/js/back-to-top.js"></script>

  
  <script src="/js/theme-toggle.js"></script>
</body>
</html>
