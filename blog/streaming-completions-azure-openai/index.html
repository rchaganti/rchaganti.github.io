<!DOCTYPE html>
<html lang="en">

  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv="Content-Language" content="en">
    <script src="https://ravichaganti.com/js/view.js"></script>
    <link rel="stylesheet" href="https://ravichaganti.com/css/syntax.css">
    <meta name="author" content="Ravikanth Chaganti">
    <meta name="description" content="Responses are streamed to the user interface as they are generated using ChatGPT and similar tools. This eliminates the need for the user to wait until the complete response is generated. In today&rsquo;s article, we shall look at streaming LLM-generated responses when using Azure OpenAI API in Python. In the earlier part of this series, we learned about the client.completions.create() function used to send a prompt to the LLM and retrieve one or more responses.">
    <meta name="keywords" content="blog,microsoft,mvp,powershell,automation,author, innovator, speaker">

    <meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Streaming model responses when using Azure OpenAI"/>
<meta name="twitter:description" content="Responses are streamed to the user interface as they are generated using ChatGPT and similar tools. This eliminates the need for the user to wait until the complete response is generated. In today&rsquo;s article, we shall look at streaming LLM-generated responses when using Azure OpenAI API in Python. In the earlier part of this series, we learned about the client.completions.create() function used to send a prompt to the LLM and retrieve one or more responses."/>

    <meta property="og:title" content="Streaming model responses when using Azure OpenAI" />
<meta property="og:description" content="Responses are streamed to the user interface as they are generated using ChatGPT and similar tools. This eliminates the need for the user to wait until the complete response is generated. In today&rsquo;s article, we shall look at streaming LLM-generated responses when using Azure OpenAI API in Python. In the earlier part of this series, we learned about the client.completions.create() function used to send a prompt to the LLM and retrieve one or more responses." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://ravichaganti.com/blog/streaming-completions-azure-openai/" />
<meta property="article:published_time" content="2024-08-04T00:00:00+00:00" />
<meta property="article:modified_time" content="2024-08-04T00:00:00+00:00" /><meta property="og:see_also" content="https://ravichaganti.com/blog/building-a-model-context-protocol-server-for-azure/" /><meta property="og:see_also" content="https://ravichaganti.com/blog/predicted-outputs-azure-openai/" /><meta property="og:see_also" content="https://ravichaganti.com/blog/parallel-tool-calling-azure-openai/" /><meta property="og:see_also" content="https://ravichaganti.com/blog/structured-output-azure-openai/" /><meta property="og:see_also" content="https://ravichaganti.com/blog/azure-openai-function-calling-with-multiple-tools/" /><meta property="og:see_also" content="https://ravichaganti.com/blog/azure-openai-function-calling/" />
<meta property="og:see_also" content="https://ravichaganti.com/blog/predicted-outputs-azure-openai/" /><meta property="og:see_also" content="https://ravichaganti.com/blog/parallel-tool-calling-azure-openai/" /><meta property="og:see_also" content="https://ravichaganti.com/blog/structured-output-azure-openai/" /><meta property="og:see_also" content="https://ravichaganti.com/blog/azure-openai-function-calling-with-multiple-tools/" /><meta property="og:see_also" content="https://ravichaganti.com/blog/azure-openai-function-calling/" /><meta property="og:see_also" content="https://ravichaganti.com/blog/using-chat-completion-api-azure-openai/" />
<meta property="og:see_also" content="https://ravichaganti.com/blog/changes-in-autogen-release-0_5_1/" /><meta property="og:see_also" content="https://ravichaganti.com/blog/teams-of-agents-in-autogen/" /><meta property="og:see_also" content="https://ravichaganti.com/blog/getting-started-with-autogen-framework-for-building-ai-agents-and-applications/" /><meta property="og:see_also" content="https://ravichaganti.com/blog/predicted-outputs-azure-openai/" /><meta property="og:see_also" content="https://ravichaganti.com/blog/parallel-tool-calling-azure-openai/" /><meta property="og:see_also" content="https://ravichaganti.com/blog/structured-output-azure-openai/" />



    
      <base href="https://ravichaganti.com/blog/streaming-completions-azure-openai/">
    
    <title>
  Streaming model responses when using Azure OpenAI · Ravikanth Chaganti
</title>

    
      <link rel="canonical" href="https://ravichaganti.com/blog/streaming-completions-azure-openai/">
    

    <link href="https://fonts.googleapis.com/css?family=Lato:400,700%7CMerriweather:300,700%7CSource+Code+Pro:400,700&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.13.0/css/all.css" integrity="sha384-Bfad6CLCknfcloXFOyFnlgtENryhrpZCe29RTifKEixXQZ38WheV+i/6YWSzkz3V" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/normalize/8.0.1/normalize.min.css" integrity="sha256-l85OmPOjvil/SOvVt3HnSSjzF1TUMyT9eV0c2BzEGzU=" crossorigin="anonymous" />

    
      
      
      <link rel="stylesheet" href="https://ravichaganti.com/css/coder.min.897f2f761ca1c7df1614de4c088e4ebbb7f5984b520994e5ee0a0fc4ba52f7de.css" integrity="sha256-iX8vdhyhx98WFN5MCI5Ou7f1mEtSCZTl7goPxLpS994=" crossorigin="anonymous" media="screen" />
    

    

    
      
        
        
        <link rel="stylesheet" href="https://ravichaganti.com/css/coder-dark.min.e78e80fc3a585a4d1c8fc7f58623b6ff852411e38431a9cd1792877ecaa160f6.css" integrity="sha256-546A/DpYWk0cj8f1hiO2/4UkEeOEManNF5KHfsqhYPY=" crossorigin="anonymous" media="screen" />
      
    

    

    

    <link rel="icon" type="image/png" href="https://ravichaganti.com/images/favicon-32x32.png" sizes="32x32">
    <link rel="icon" type="image/png" href="https://ravichaganti.com/images/favicon-16x16.png" sizes="16x16">

    <meta name="generator" content="Hugo 0.73.0" />
  </head>

  
  
    
  
  
    <body onload="getViews( &#34;https://ravichaganti.com/blog/streaming-completions-azure-openai/&#34; )" class="colorscheme-auto">
  
    <main class="wrapper">
      <nav class="navigation">
  <section class="container">
    <a class="navigation-title" href="https://ravichaganti.com/">
      Ravikanth Chaganti
    </a>
    
    <input type="checkbox" id="menu-toggle" />
    <label class="menu-button float-right" for="menu-toggle"><i class="fas fa-bars"></i></label>
    <ul class="navigation-list">
      
        
          <li class="navigation-item">
            <a class="navigation-link" href="https://ravichaganti.com/about/">About</a>
          </li>
        
          <li class="navigation-item">
            <a class="navigation-link" href="https://ravichaganti.com/blog/">Blog</a>
          </li>
        
          <li class="navigation-item">
            <a class="navigation-link" href="https://ravichaganti.com/books/">Books</a>
          </li>
        
      
      
    </ul>
    
  </section>
</nav>


      <div class="content">
        
  <section class="container post">
    <article>
      <header>
        <div class="post-title">
          <h1 class="title">Streaming model responses when using Azure OpenAI</h1>
        </div>
        <div class="post-meta">
          <div class="date">
            <span class="posted-on">
              <i class="fas fa-calendar"></i>
              <time datetime='2024-08-04T00:00:00Z'>
                August 4, 2024
              </time>
            </span>
            <span class="reading-time">
              <i class="fas fa-clock"></i>
              3-minute read
            </span>
          </div>
          <div class="categories">
  <i class="fas fa-folder"></i>
    <a href="https://ravichaganti.com/categories/azure/">azure</a>
      <span class="separator">•</span>
    <a href="https://ravichaganti.com/categories/openai/">openai</a>
      <span class="separator">•</span>
    <a href="https://ravichaganti.com/categories/python/">python</a></div>

          <div class="tags">
  <i class="fas fa-tag"></i>
    <a href="https://ravichaganti.com/tags/azure/">azure</a>
      <span class="separator">•</span>
    <a href="https://ravichaganti.com/tags/openai/">openai</a>
      <span class="separator">•</span>
    <a href="https://ravichaganti.com/tags/python/">python</a></div>

        </div>
      </header>
      <hr>
      <div>
        
        
        <p>Responses are streamed to the user interface as they are generated using ChatGPT and similar tools. This eliminates the need for the user to wait until the complete response is generated. In today&rsquo;s article, we shall look at streaming LLM-generated responses when using Azure OpenAI API in Python.  In the earlier part of <a href="https://ravichaganti.com/series/azure-openai/">this series</a>, we learned about the <code>client.completions.create()</code> function used to send a prompt to the LLM and retrieve one or more responses. This function supports a parameter called <code>stream</code> when set to <code>True</code>, asks LLM to stream the response as it gets generated. The way to handle this response is a bit different from a standard completion response.</p>
<p>Let us take a look at the example.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">dotenv</span> <span class="kn">import</span> <span class="n">load_dotenv</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">from</span> <span class="nn">openai</span> <span class="kn">import</span> <span class="n">AzureOpenAI</span>

<span class="n">load_dotenv</span><span class="p">()</span>

<span class="n">AZURE_OPENAI_API_KEY_FOR_INSTRUCT</span><span class="o">=</span><span class="n">os</span><span class="o">.</span><span class="n">getenv</span><span class="p">(</span><span class="s2">&#34;AZURE_OPENAI_API_KEY_FOR_INSTRUCT&#34;</span><span class="p">)</span>
<span class="n">AZURE_OPENAI_ENDPOINT_FOR_INSTRUCT</span><span class="o">=</span><span class="n">os</span><span class="o">.</span><span class="n">getenv</span><span class="p">(</span><span class="s2">&#34;AZURE_OPENAI_ENDPOINT_FOR_INSTRUCT&#34;</span><span class="p">)</span>
<span class="n">AZURE_OPENAI_DEPLOYMENT_NAME_FOR_INSTRUCT</span><span class="o">=</span><span class="n">os</span><span class="o">.</span><span class="n">getenv</span><span class="p">(</span><span class="s2">&#34;AZURE_OPENAI_DEPLOYMENT_NAME_FOR_INSTRUCT&#34;</span><span class="p">)</span>
    
<span class="n">client</span> <span class="o">=</span> <span class="n">AzureOpenAI</span><span class="p">(</span>
    <span class="n">api_key</span><span class="o">=</span><span class="n">os</span><span class="o">.</span><span class="n">getenv</span><span class="p">(</span><span class="s2">&#34;AZURE_OPENAI_API_KEY_FOR_INSTRUCT&#34;</span><span class="p">),</span>  
    <span class="n">api_version</span><span class="o">=</span><span class="s2">&#34;2024-02-01&#34;</span><span class="p">,</span>
    <span class="n">azure_endpoint</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">getenv</span><span class="p">(</span><span class="s2">&#34;AZURE_OPENAI_ENDPOINT_FOR_INSTRUCT&#34;</span><span class="p">)</span>
<span class="p">)</span>
    
<span class="n">start_phrase</span> <span class="o">=</span> <span class="s1">&#39;What is the transformer architecture? Explain self-attention mechanism. Provide the response in 5 bullet points.&#39;</span>
<span class="n">response</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="n">completions</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
    <span class="n">model</span><span class="o">=</span><span class="n">AZURE_OPENAI_DEPLOYMENT_NAME_FOR_INSTRUCT</span><span class="p">,</span> 
    <span class="n">prompt</span><span class="o">=</span><span class="n">start_phrase</span><span class="p">,</span>
    <span class="n">max_tokens</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
    <span class="n">stream</span><span class="o">=</span><span class="bp">True</span>
<span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="n">start_phrase</span><span class="p">)</span>

<span class="k">for</span> <span class="n">chunk</span> <span class="ow">in</span> <span class="n">response</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">chunk</span><span class="o">.</span><span class="n">choices</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">chunk</span><span class="o">.</span><span class="n">choices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">finish_reason</span> <span class="o">!=</span> <span class="s1">&#39;stop&#39;</span><span class="p">:</span>
            <span class="n">text</span> <span class="o">=</span> <span class="n">chunk</span><span class="o">.</span><span class="n">choices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">text</span>
            <span class="k">print</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">)</span>
</code></pre></td></tr></table>
</div>
</div><p>In this example, the response arrives at the client as chunks. Each chunk needs to be read to retrieve the partially generated response. Each chunk contains a <code>finish_reason</code> to determine when to stop iterating (<code>finish_reason == 'stop'</code>) over the chunks. The <code>print()</code> function appends a new line when printing the chunk. As these are partially generated responses, adding a new line makes the output unreadable. We, therefore, set the <code>end</code> parameter of the <code>''</code>.</p>
<p>When we run this program, you can see words and lines streamed to the console.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span><span class="lnt">8
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell"><span class="o">(</span>.venv<span class="o">)</span> PS C:<span class="se">\&gt;</span> python.exe .<span class="se">\0</span>2_completion_stream.py
What is the transformer architecture? Explain self-attention mechanism. Provide the response in <span class="m">5</span> bullet points.

1. The transformer architecture is a <span class="nb">type</span> of neural network used <span class="k">for</span> natural language processing tasks such as machine translation and text generation.
2. It was introduced by Google in <span class="m">2017</span> and has since become one of the most popular architectures <span class="k">for</span> NLP tasks due to its ability to handle long sequences and avoid the use of recurrent neural networks.
3. Rather than using recurrent connections, the transformer architecture uses self-attention mechanisms to process input sequences and make predictions.
4. The self-attention mechanism allows the model to focus on specific parts of the input sequence, learning the relationship between different words in a sentence and capturing dependencies between words that are far apart.
5. This is achieved by calculating a weighted sum of the input sequence where the weights are determined by the relevance of each word in the sequence to the current word being processed. This allows the model to learn contextual information and make better predictions <span class="k">for</span> each word in the sequence.
</code></pre></td></tr></table>
</div>
</div><p>In this part, you learned how to stream the responses and deal with the response chunks to build meaningful output. In the next part, we shall look at how to use the chat completion API to build a conversation with the LLM.</p>

        

<style>
#share-buttons {display: inline-block; vertical-align: middle; }
#share-buttons:after {content: ""; display: block; clear: both;}
#share-buttons > div {
position: relative;
text-align: left; 
height: 36px; 
width: 32px; 
float: left; 
text-align: center;
}
#share-buttons > div > svg {height: 16px; fill: #d5d5d5; margin-top: 10px;}
#share-buttons > div:hover {cursor: pointer;}
#share-buttons > div.facebook:hover > svg {fill: #3B5998;}
#share-buttons > div.twitter:hover > svg {fill: #55ACEE;}
#share-buttons > div.linkedin:hover > svg {fill: #0077b5;}
#share-buttons > div.pinterest:hover > svg {fill: #CB2027;}
#share-buttons > div.gplus:hover > svg {fill: #dd4b39;}
#share-buttons > div.mail:hover > svg {fill: #7D7D7D;}
#share-buttons > div.instagram:hover > svg {fill: #C73B92;}
#share-buttons > div.facebook > svg {height: 18px; margin-top: 9px;}
#share-buttons > div.twitter > svg {height: 20px; margin-top: 8px;}
#share-buttons > div.linkedin > svg {height: 19px; margin-top: 7px;}
#share-buttons > div.pinterest > svg {height: 20px; margin-top: 9px;}
#share-buttons > div.gplus > svg {height: 17px; margin-top: 9px; position: relative; left: 1px;}
#share-buttons > div.mail > svg {height: 14px; margin-top: 11px;}
</style>

<span style="color: rgb(77, 77, 95);">Share on: </span><div id="share-buttons">
<div class="facebook" title="Share this on Facebook" onclick="window.open('https://www.facebook.com/sharer/sharer.php?u=https:\/\/ravichaganti.com\/blog\/streaming-completions-azure-openai\/');"><svg viewBox="0 0 1792 1792" xmlns="http://www.w3.org/2000/svg"><path d="M1343 12v264h-157q-86 0-116 36t-30 108v189h293l-39 296h-254v759h-306v-759h-255v-296h255v-218q0-186 104-288.5t277-102.5q147 0 228 12z"/></svg></div>
<div class="twitter" title="Share this on Twitter" onclick="window.open('https://twitter.com/intent/tweet?text=https:\/\/ravichaganti.com\/blog\/streaming-completions-azure-openai\/');"><svg viewBox="0 0 1792 1792" xmlns="http://www.w3.org/2000/svg"><path d="M1684 408q-67 98-162 167 1 14 1 42 0 130-38 259.5t-115.5 248.5-184.5 210.5-258 146-323 54.5q-271 0-496-145 35 4 78 4 225 0 401-138-105-2-188-64.5t-114-159.5q33 5 61 5 43 0 85-11-112-23-185.5-111.5t-73.5-205.5v-4q68 38 146 41-66-44-105-115t-39-154q0-88 44-163 121 149 294.5 238.5t371.5 99.5q-8-38-8-74 0-134 94.5-228.5t228.5-94.5q140 0 236 102 109-21 205-78-37 115-142 178 93-10 186-50z"/></svg></div>
<div class="linkedin" title="Share this on Linkedin" onclick="window.open('https://www.linkedin.com/sharing/share-offsite/?url=https:\/\/ravichaganti.com\/blog\/streaming-completions-azure-openai\/');"><svg viewBox="0 0 1792 1792" xmlns="http://www.w3.org/2000/svg"><path d="M477 625v991h-330v-991h330zm21-306q1 73-50.5 122t-135.5 49h-2q-82 0-132-49t-50-122q0-74 51.5-122.5t134.5-48.5 133 48.5 51 122.5zm1166 729v568h-329v-530q0-105-40.5-164.5t-126.5-59.5q-63 0-105.5 34.5t-63.5 85.5q-11 30-11 81v553h-329q2-399 2-647t-1-296l-1-48h329v144h-2q20-32 41-56t56.5-52 87-43.5 114.5-15.5q171 0 275 113.5t104 332.5z"/></svg></div>
<div class="mail" title="Share this through Email" onclick="window.open('mailto:?&body=https:\/\/ravichaganti.com\/blog\/streaming-completions-azure-openai\/');"><svg viewBox="0 0 1792 1792" xmlns="http://www.w3.org/2000/svg"><path d="M1792 710v794q0 66-47 113t-113 47h-1472q-66 0-113-47t-47-113v-794q44 49 101 87 362 246 497 345 57 42 92.5 65.5t94.5 48 110 24.5h2q51 0 110-24.5t94.5-48 92.5-65.5q170-123 498-345 57-39 100-87zm0-294q0 79-49 151t-122 123q-376 261-468 325-10 7-42.5 30.5t-54 38-52 32.5-57.5 27-50 9h-2q-23 0-50-9t-57.5-27-52-32.5-54-38-42.5-30.5q-91-64-262-182.5t-205-142.5q-62-42-117-115.5t-55-136.5q0-78 41.5-130t118.5-52h1472q65 0 112.5 47t47.5 113z"/></svg></div>
</div>
        <script src="https://giscus.app/client.js"
        data-repo="rchaganti/rchaganti.github.io"
        data-repo-id="MDEwOlJlcG9zaXRvcnkyNzcwNTE0Mjc="
        data-category="Announcements"
        data-category-id="DIC_kwDOEIN4I84CS4rW"
        data-mapping="pathname"
        data-strict="1"
        data-reactions-enabled="1"
        data-emit-metadata="0"
        data-input-position="top"
        data-theme="light"
        data-lang="en"
        data-loading="lazy"
        crossorigin="anonymous"
        async>
</script>
      </div>


      <footer>
        

<section class="see-also">
  
    
    
    
      <h3>See also in azure</h3>
      <nav>
        <ul>
        
        
          
            <li>
              <a href="https://ravichaganti.com/blog/building-a-model-context-protocol-server-for-azure/">Building a Model Context Protocol server for Azure</a>
            </li>
          
        
          
            <li>
              <a href="https://ravichaganti.com/blog/predicted-outputs-azure-openai/">Predicted outputs in Azure OpenAI</a>
            </li>
          
        
          
            <li>
              <a href="https://ravichaganti.com/blog/parallel-tool-calling-azure-openai/">Parallel tool calling in Azure OpenAI</a>
            </li>
          
        
          
            <li>
              <a href="https://ravichaganti.com/blog/structured-output-azure-openai/">Structured output in Azure OpenAI</a>
            </li>
          
        
          
            <li>
              <a href="https://ravichaganti.com/blog/azure-openai-function-calling-with-multiple-tools/">Implementing multiple tool/function calling when using Azure OpenAI</a>
            </li>
          
        
          
            <li>
              <a href="https://ravichaganti.com/blog/azure-openai-function-calling/">Implementing tool/function calling when using Azure OpenAI</a>
            </li>
          
        
        </ul>
      </nav>
    
  
    
    
    
      <h3>See also in openai</h3>
      <nav>
        <ul>
        
        
          
            <li>
              <a href="https://ravichaganti.com/blog/predicted-outputs-azure-openai/">Predicted outputs in Azure OpenAI</a>
            </li>
          
        
          
            <li>
              <a href="https://ravichaganti.com/blog/parallel-tool-calling-azure-openai/">Parallel tool calling in Azure OpenAI</a>
            </li>
          
        
          
            <li>
              <a href="https://ravichaganti.com/blog/structured-output-azure-openai/">Structured output in Azure OpenAI</a>
            </li>
          
        
          
            <li>
              <a href="https://ravichaganti.com/blog/azure-openai-function-calling-with-multiple-tools/">Implementing multiple tool/function calling when using Azure OpenAI</a>
            </li>
          
        
          
            <li>
              <a href="https://ravichaganti.com/blog/azure-openai-function-calling/">Implementing tool/function calling when using Azure OpenAI</a>
            </li>
          
        
          
            <li>
              <a href="https://ravichaganti.com/blog/using-chat-completion-api-azure-openai/">Using chat completion API in Azure OpenAI</a>
            </li>
          
        
        </ul>
      </nav>
    
  
    
    
    
      <h3>See also in azure-openai</h3>
      <nav>
        <ul>
        
        
          
            <li>
              <a href="https://ravichaganti.com/blog/changes-in-autogen-release-0_5_1/">Changes in Autogen release 0.5.1</a>
            </li>
          
        
          
            <li>
              <a href="https://ravichaganti.com/blog/teams-of-agents-in-autogen/">Teams of agents in AutoGen</a>
            </li>
          
        
          
            <li>
              <a href="https://ravichaganti.com/blog/getting-started-with-autogen-framework-for-building-ai-agents-and-applications/">Getting started with AutoGen framework for building AI agents and applications</a>
            </li>
          
        
          
            <li>
              <a href="https://ravichaganti.com/blog/predicted-outputs-azure-openai/">Predicted outputs in Azure OpenAI</a>
            </li>
          
        
          
            <li>
              <a href="https://ravichaganti.com/blog/parallel-tool-calling-azure-openai/">Parallel tool calling in Azure OpenAI</a>
            </li>
          
        
          
            <li>
              <a href="https://ravichaganti.com/blog/structured-output-azure-openai/">Structured output in Azure OpenAI</a>
            </li>
          
        
        </ul>
      </nav>
    
  
</section>


        
        <script data-goatcounter="https://ravichaganti.goatcounter.com/count" async src="https://gc.zgo.at/count.js"></script>
      </footer>
    </article>

    
  </section>

      </div>
      <script data-goatcounter="https://ravichaganti.goatcounter.com/count" async src="https://gc.zgo.at/count.js"></script>
      
  <footer class="footer">
    <section class="container">
      
        <p>All Rights Reserved.</p>
      
      
        ©
        
          2019 -
        
        2025
         Ravikanth Chaganti 
      
      
         · 
        Powered by <a href="https://gohugo.io/">Hugo</a> & <a href="https://github.com/luizdepra/hugo-coder/">Coder</a> and hosted using <a href="https://pages.github.com/">GitHub Pages</a>.
      
      
    </section>
  </footer>

    </main>

        
    
    

  </body>

</html>
